{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cornell-birds-training_TF.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPLhl9TuE9COqguHNPbavWZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benayas1/ALV_Framework/blob/master/cornell_birds_training_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI1dM5_TnFCG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c7d72046-ca8d-4f3a-a1a2-3d000869f446"
      },
      "source": [
        "# Import apex for mixed precision training\n",
        "#!cd /kaggle/input/apexpytorch/ && pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./ >> /dev/null\n",
        "\n",
        "#!wget https://github.com/benayas1/benatools/archive/master.zip -P bena\n",
        "#!unzip bena/master.zip\n",
        "\n",
        "!pip install benatools >> /dev/null\n",
        "\n",
        "# Install resnest\n",
        "#!pip install ../input/resnest50-fast-package/resnest-0.0.6b20200701/resnest/ >> /dev/null\n",
        "!pip install soundfile\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from pathlib import Path\n",
        "import typing as tp\n",
        "import cv2\n",
        "import librosa\n",
        "import random\n",
        "import audioread\n",
        "import soundfile as sf\n",
        "import os\n",
        "import time as time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import benatools as bena\n",
        "from benatools.tools import MultiStratifiedKFold\n",
        "from benatools.tf.efficient_net import create_efn\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "!pip install gcsfs\n",
        "import gcsfs\n",
        "from google.colab import auth\n",
        "from google.cloud import storage\n",
        "\n",
        "\n",
        "#from apex import amp\n",
        "\n",
        "#import resnest.torch as resnest_torch\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "\n",
        "COLAB = True\n",
        "\n",
        "if COLAB:\n",
        "    os.environ.setdefault(\"GCLOUD_PROJECT\", \"omega-cosmos-116215\")\n",
        "    GS_BUCKET = 'benayas_kaggle'\n",
        "    !echo \"deb http://packages.cloud.google.com/apt gcsfuse-`lsb_release -c -s` main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list\n",
        "    !curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "    !sudo apt-get -y -q update\n",
        "    !sudo apt-get -y -q install gcsfuse\n",
        "    auth.authenticate_user()\n",
        "    !mkdir -p data\n",
        "    !gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 {GS_BUCKET} data"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.6/dist-packages (0.10.3.post1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gcsfs) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.4.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from gcsfs) (4.4.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.6/dist-packages (from gcsfs) (3.6.2)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (1.17.2)\n",
            "Requirement already satisfied: fsspec>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2.10)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (1.5.1)\n",
            "Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (1.1.0)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (3.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (19.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (3.7.4.2)\n",
            "Requirement already satisfied: multidict<5.0,>=4.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (4.7.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (49.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.6)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.8)\n",
            "deb http://packages.cloud.google.com/apt gcsfuse-bionic main\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   653  100   653    0     0  21064      0 --:--:-- --:--:-- --:--:-- 21766\n",
            "OK\n",
            "Hit:1 http://packages.cloud.google.com/apt gcsfuse-bionic InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:7 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:13 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "gcsfuse is already the newest version (0.30.0).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 60 not upgraded.\n",
            "Using mount point: /content/data\n",
            "Opening GCS connection...\n",
            "Opening bucket...\n",
            "Mounting file system...\n",
            "daemonize.Run: readFromProcess: sub-process: mountWithArgs: mountWithConn: Mount: mount: running fusermount: exit status 1\n",
            "\n",
            "stderr:\n",
            "fusermount: mountpoint is not empty\n",
            "fusermount: if you are sure this is safe, use the 'nonempty' mount option\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz6eDyk4nQ0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Seed\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    tf.random.set_seed(seed)\n",
        "    \n",
        "seed_everything(42)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H0wCAbEo1UZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        },
        "outputId": "3a3f90c6-2f69-4294-c3b4-729ceb73fc96"
      },
      "source": [
        "DEVICE = \"TPU\"\n",
        "\n",
        "if DEVICE == \"TPU\":\n",
        "    print(\"connecting to TPU...\")\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "        print('Running on TPU ', tpu.master())\n",
        "    except ValueError:\n",
        "        print(\"Could not connect to TPU\")\n",
        "        tpu = None\n",
        "\n",
        "    if tpu:\n",
        "        try:\n",
        "            print(\"initializing  TPU ...\")\n",
        "            tf.config.experimental_connect_to_cluster(tpu)\n",
        "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "            strategy = tf.distribute.TPUStrategy(tpu)\n",
        "            print(\"TPU initialized\")\n",
        "        except _:\n",
        "            print(\"failed to initialize TPU\")\n",
        "    else:\n",
        "        DEVICE = \"GPU\"\n",
        "\n",
        "if DEVICE != \"TPU\":\n",
        "    print(\"Using default strategy for CPU and single GPU\")\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "if DEVICE == \"GPU\":\n",
        "    print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "    \n",
        "\n",
        "AUTO     = tf.data.experimental.AUTOTUNE\n",
        "REPLICAS = strategy.num_replicas_in_sync\n",
        "print(f'REPLICAS: {REPLICAS}')"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "connecting to TPU...\n",
            "Running on TPU  grpc://10.14.219.26:8470\n",
            "initializing  TPU ...\n",
            "WARNING:tensorflow:TPU system grpc://10.14.219.26:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.14.219.26:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.14.219.26:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.14.219.26:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TPU initialized\n",
            "REPLICAS: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6pozhS6oOIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Coding the bird names\n",
        "\n",
        "BIRD_CODE = {\n",
        "    'aldfly': 0, 'ameavo': 1, 'amebit': 2, 'amecro': 3, 'amegfi': 4,\n",
        "    'amekes': 5, 'amepip': 6, 'amered': 7, 'amerob': 8, 'amewig': 9,\n",
        "    'amewoo': 10, 'amtspa': 11, 'annhum': 12, 'astfly': 13, 'baisan': 14,\n",
        "    'baleag': 15, 'balori': 16, 'banswa': 17, 'barswa': 18, 'bawwar': 19,\n",
        "    'belkin1': 20, 'belspa2': 21, 'bewwre': 22, 'bkbcuc': 23, 'bkbmag1': 24,\n",
        "    'bkbwar': 25, 'bkcchi': 26, 'bkchum': 27, 'bkhgro': 28, 'bkpwar': 29,\n",
        "    'bktspa': 30, 'blkpho': 31, 'blugrb1': 32, 'blujay': 33, 'bnhcow': 34,\n",
        "    'boboli': 35, 'bongul': 36, 'brdowl': 37, 'brebla': 38, 'brespa': 39,\n",
        "    'brncre': 40, 'brnthr': 41, 'brthum': 42, 'brwhaw': 43, 'btbwar': 44,\n",
        "    'btnwar': 45, 'btywar': 46, 'buffle': 47, 'buggna': 48, 'buhvir': 49,\n",
        "    'bulori': 50, 'bushti': 51, 'buwtea': 52, 'buwwar': 53, 'cacwre': 54,\n",
        "    'calgul': 55, 'calqua': 56, 'camwar': 57, 'cangoo': 58, 'canwar': 59,\n",
        "    'canwre': 60, 'carwre': 61, 'casfin': 62, 'caster1': 63, 'casvir': 64,\n",
        "    'cedwax': 65, 'chispa': 66, 'chiswi': 67, 'chswar': 68, 'chukar': 69,\n",
        "    'clanut': 70, 'cliswa': 71, 'comgol': 72, 'comgra': 73, 'comloo': 74,\n",
        "    'commer': 75, 'comnig': 76, 'comrav': 77, 'comred': 78, 'comter': 79,\n",
        "    'comyel': 80, 'coohaw': 81, 'coshum': 82, 'cowscj1': 83, 'daejun': 84,\n",
        "    'doccor': 85, 'dowwoo': 86, 'dusfly': 87, 'eargre': 88, 'easblu': 89,\n",
        "    'easkin': 90, 'easmea': 91, 'easpho': 92, 'eastow': 93, 'eawpew': 94,\n",
        "    'eucdov': 95, 'eursta': 96, 'evegro': 97, 'fiespa': 98, 'fiscro': 99,\n",
        "    'foxspa': 100, 'gadwal': 101, 'gcrfin': 102, 'gnttow': 103, 'gnwtea': 104,\n",
        "    'gockin': 105, 'gocspa': 106, 'goleag': 107, 'grbher3': 108, 'grcfly': 109,\n",
        "    'greegr': 110, 'greroa': 111, 'greyel': 112, 'grhowl': 113, 'grnher': 114,\n",
        "    'grtgra': 115, 'grycat': 116, 'gryfly': 117, 'haiwoo': 118, 'hamfly': 119,\n",
        "    'hergul': 120, 'herthr': 121, 'hoomer': 122, 'hoowar': 123, 'horgre': 124,\n",
        "    'horlar': 125, 'houfin': 126, 'houspa': 127, 'houwre': 128, 'indbun': 129,\n",
        "    'juntit1': 130, 'killde': 131, 'labwoo': 132, 'larspa': 133, 'lazbun': 134,\n",
        "    'leabit': 135, 'leafly': 136, 'leasan': 137, 'lecthr': 138, 'lesgol': 139,\n",
        "    'lesnig': 140, 'lesyel': 141, 'lewwoo': 142, 'linspa': 143, 'lobcur': 144,\n",
        "    'lobdow': 145, 'logshr': 146, 'lotduc': 147, 'louwat': 148, 'macwar': 149,\n",
        "    'magwar': 150, 'mallar3': 151, 'marwre': 152, 'merlin': 153, 'moublu': 154,\n",
        "    'mouchi': 155, 'moudov': 156, 'norcar': 157, 'norfli': 158, 'norhar2': 159,\n",
        "    'normoc': 160, 'norpar': 161, 'norpin': 162, 'norsho': 163, 'norwat': 164,\n",
        "    'nrwswa': 165, 'nutwoo': 166, 'olsfly': 167, 'orcwar': 168, 'osprey': 169,\n",
        "    'ovenbi1': 170, 'palwar': 171, 'pasfly': 172, 'pecsan': 173, 'perfal': 174,\n",
        "    'phaino': 175, 'pibgre': 176, 'pilwoo': 177, 'pingro': 178, 'pinjay': 179,\n",
        "    'pinsis': 180, 'pinwar': 181, 'plsvir': 182, 'prawar': 183, 'purfin': 184,\n",
        "    'pygnut': 185, 'rebmer': 186, 'rebnut': 187, 'rebsap': 188, 'rebwoo': 189,\n",
        "    'redcro': 190, 'redhea': 191, 'reevir1': 192, 'renpha': 193, 'reshaw': 194,\n",
        "    'rethaw': 195, 'rewbla': 196, 'ribgul': 197, 'rinduc': 198, 'robgro': 199,\n",
        "    'rocpig': 200, 'rocwre': 201, 'rthhum': 202, 'ruckin': 203, 'rudduc': 204,\n",
        "    'rufgro': 205, 'rufhum': 206, 'rusbla': 207, 'sagspa1': 208, 'sagthr': 209,\n",
        "    'savspa': 210, 'saypho': 211, 'scatan': 212, 'scoori': 213, 'semplo': 214,\n",
        "    'semsan': 215, 'sheowl': 216, 'shshaw': 217, 'snobun': 218, 'snogoo': 219,\n",
        "    'solsan': 220, 'sonspa': 221, 'sora': 222, 'sposan': 223, 'spotow': 224,\n",
        "    'stejay': 225, 'swahaw': 226, 'swaspa': 227, 'swathr': 228, 'treswa': 229,\n",
        "    'truswa': 230, 'tuftit': 231, 'tunswa': 232, 'veery': 233, 'vesspa': 234,\n",
        "    'vigswa': 235, 'warvir': 236, 'wesblu': 237, 'wesgre': 238, 'weskin': 239,\n",
        "    'wesmea': 240, 'wessan': 241, 'westan': 242, 'wewpew': 243, 'whbnut': 244,\n",
        "    'whcspa': 245, 'whfibi': 246, 'whtspa': 247, 'whtswi': 248, 'wilfly': 249,\n",
        "    'wilsni1': 250, 'wiltur': 251, 'winwre3': 252, 'wlswar': 253, 'wooduc': 254,\n",
        "    'wooscj2': 255, 'woothr': 256, 'y00475': 257, 'yebfly': 258, 'yebsap': 259,\n",
        "    'yehbla': 260, 'yelwar': 261, 'yerwar': 262, 'yetvir': 263\n",
        "}\n",
        "\n",
        "INV_BIRD_CODE = {v: k for k, v in BIRD_CODE.items()}"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOd-aL1EmNcd",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxXWUyVSnyN5",
        "colab_type": "text"
      },
      "source": [
        "Get all TFRecords paths from GS bucket, which are already classified by fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q98vpflUmQM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FOLDS = 5\n",
        "GCS_PATH  = \"gs://benayas_kaggle/birdsongs_recognition_tf/\"\n",
        "files_fold = { i: np.sort(np.array(tf.io.gfile.glob(GCS_PATH+\"fold_\"+str(i)+\"*.tfrec\"))) for i in range(FOLDS) }"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHZeM-b5pisz",
        "colab_type": "text"
      },
      "source": [
        "Functions to convert audio to spectrogram image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17k7WZZcphMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mono_to_color(\n",
        "    X, mean=None, std=None,\n",
        "    norm_max=None, norm_min=None, eps=1e-6\n",
        "):\n",
        "    # Stack X as [X,X,X]\n",
        "    X = np.stack([X, X, X], axis=-1)\n",
        "\n",
        "    # Standardize\n",
        "    mean = mean or X.mean()\n",
        "    X = X - mean\n",
        "    std = std or X.std()\n",
        "    Xstd = X / (std + eps)\n",
        "    _min, _max = Xstd.min(), Xstd.max()\n",
        "    norm_max = norm_max or _max\n",
        "    norm_min = norm_min or _min\n",
        "    if (_max - _min) > eps:\n",
        "        # Normalize to [0, 255]\n",
        "        V = Xstd\n",
        "        V[V < norm_min] = norm_min\n",
        "        V[V > norm_max] = norm_max\n",
        "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
        "        V = V.astype(np.uint8)\n",
        "    else:\n",
        "        # Just zero\n",
        "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
        "    return V\n",
        "\n",
        "def read_file(y, sr, ebird_code, period=5, img_size = 224, waveform_transforms=None, melspectrogram_parameters=None, spectrogram_transforms=None, one_hot_label=True, labeled=True):\n",
        "\n",
        "        if waveform_transforms:\n",
        "            y = waveform_transforms(y)\n",
        "        else:\n",
        "            len_y = len(y)\n",
        "            effective_length = sr * period\n",
        "            if len_y < effective_length:\n",
        "                new_y = np.zeros(effective_length, dtype=y.dtype)\n",
        "                start = np.random.randint(effective_length - len_y)\n",
        "                new_y[start:start + len_y] = y\n",
        "                y = new_y.astype(np.float32)\n",
        "            elif len_y > effective_length:\n",
        "                start = np.random.randint(len_y - effective_length)\n",
        "                y = y[start:start + effective_length].astype(np.float32)\n",
        "            else:\n",
        "                y = y.astype(np.float32)\n",
        "\n",
        "        melspec = librosa.feature.melspectrogram(y, sr=sr, **melspectrogram_parameters)\n",
        "        melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
        "        \n",
        "        librosa.display.specshow(melspec, sr=sr)\n",
        "\n",
        "        if spectrogram_transforms:\n",
        "            melspec = spectrogram_transforms(melspec)\n",
        "        else:\n",
        "            pass\n",
        "                \n",
        "        image = mono_to_color(melspec)\n",
        "        height, width, _ = image.shape\n",
        "        image = cv2.resize(image, (int(width * img_size / height), img_size))\n",
        "        image = np.moveaxis(image, 2, 0)\n",
        "        image = (image / 255.0).astype(np.float32)\n",
        "\n",
        "        # Labels in One Hot format\n",
        "        if labeled:\n",
        "            s = ebird_code.numpy().decode(\"utf-8\")\n",
        "            if one_hot_label:\n",
        "                labels = np.zeros(len(BIRD_CODE), dtype=\"f\")\n",
        "                labels[BIRD_CODE[s]] = 1\n",
        "            else:  # Labels in integer format\n",
        "                labels = BIRD_CODE[s]\n",
        "\n",
        "            return image, labels\n",
        "        else:\n",
        "            return image"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDiaK_Yjps0e",
        "colab_type": "text"
      },
      "source": [
        "Functions to decode tf records and to build a tf dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1rYIb9dpZKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def read_labeled_tfrecord(ex):\n",
        "    LABELED_TFREC_FORMAT = {\n",
        "      'wav': tf.io.FixedLenFeature([], tf.string), # wav file\n",
        "      'sr': tf.io.FixedLenFeature([], tf.int64), # sr\n",
        "      'y':  tf.io.FixedLenFeature([], tf.int64), # target\n",
        "    }\n",
        "    example = tf.io.parse_single_example(ex, LABELED_TFREC_FORMAT)\n",
        "    wav = tf.io.decode_raw(example['wav'], out_type=tf.float32)\n",
        "    sr = example['sr']\n",
        "    y = example['y']\n",
        "    return wav, sr, y # returns a dataset \n",
        "\n",
        "def load_dataset(filenames, batch_size=32, labeled=True, ordered=False, melspectrogram_parameters=None):\n",
        "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
        "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
        "\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
        "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
        "    dataset = dataset.map(read_labeled_tfrecord)\n",
        "    dataset = dataset.map(lambda wav, sr, label: read_file(wav, sr, label, period=5, \n",
        "                                                           img_size = 224, \n",
        "                                                           waveform_transforms=None, \n",
        "                                                           melspectrogram_parameters=melspectrogram_parameters, \n",
        "                                                           spectrogram_transforms=None, \n",
        "                                                           one_hot_label=True, \n",
        "                                                           labeled=labeled))\n",
        "    \n",
        "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
        "    dataset = dataset.shuffle(1024*8)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        "\n",
        "def count_data_items(filenames):\n",
        "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
        "    n = [int(f[:f.rfind('.')].split('_')[-1]) for f in filenames]\n",
        "    return np.sum(n)\n",
        "\n",
        "def get_fold(fold, files_fold):\n",
        "    train_files = np.concatenate([v for k,v in files_fold.items() if k != fold])\n",
        "    val_files = files_fold[fold]\n",
        "    return train_files, val_files"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVhw7qHPskjC",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z76lprEbsnwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to be called\n",
        "def get_model(model, n_classes):\n",
        "    if model == 0:\n",
        "        return get_model0( n_classes)\n",
        "    \n",
        "    if model == 1:\n",
        "        return get_model1( n_classes)\n",
        "\n",
        "\n",
        "# Model based on efficient net B0\n",
        "def get_model0(n_classes):\n",
        "    base = create_efn(b, dim=224, include_top=False)\n",
        "\n",
        "    # # use the same head as the baseline notebook.\n",
        "    x = tf.keras.layers.Dense(512, activation='relu')(base)\n",
        "    x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
        "    x = tf.keras.layers.Dense(512, activation='relu')(base)\n",
        "    x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
        "    x = tf.keras.layers.Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inp, outputs=x)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy() \n",
        "    model.compile(optimizer=opt, loss=loss)\n",
        "    \n",
        "    return model\n",
        "\n",
        "def get_lr_callback(batch_size=8):\n",
        "    lr_start   = 0.000005\n",
        "    lr_max     = 0.00000125 * REPLICAS * batch_size\n",
        "    lr_min     = 0.000001\n",
        "    lr_ramp_ep = 5\n",
        "    lr_sus_ep  = 0\n",
        "    lr_decay   = 0.8\n",
        "   \n",
        "    def lrfn(epoch):\n",
        "        if epoch < lr_ramp_ep:\n",
        "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
        "            \n",
        "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
        "            lr = lr_max\n",
        "            \n",
        "        else:\n",
        "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
        "            \n",
        "        return lr\n",
        "\n",
        "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n",
        "    return lr_callback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfOAufbov_CJ",
        "colab_type": "text"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47XYJuRhwBJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_EXPERIMENTS = 1  # Normally not more than one run per commit\n",
        "FOLD = 0 # Each run should cover a single fold\n",
        "\n",
        "# DATASET PARAMS\n",
        "IMG_SIZE = [224] * N_EXPERIMENTS\n",
        "MELSPECTOGRAM_PARAMS = [{'n_mels':128, 'fmin':20, 'fmax':16000}] * N_EXPERIMENTS\n",
        "\n",
        "# DATALOADER PARAMS\n",
        "BS_TRAIN = [64]\n",
        "BS_VAL = [64]\n",
        "\n",
        "# MODEL PARAMS\n",
        "MODEL = [0]\n",
        "\n",
        "# LOSS FUNCTION\n",
        "LOSS = [torch.nn.CrossEntropyLoss]\n",
        "        #torch.nn.BCEWithLogitsLoss\n",
        "\n",
        "# LR SCHEDULER\n",
        "LR = [torch.optim.lr_scheduler.ReduceLROnPlateau] * N_EXPERIMENTS\n",
        "#LR = [torch.optim.lr_scheduler.CosineAnnealingLR] * N_EXPERIMENTS\n",
        "LR_PARAMS = [dict( mode='min',\n",
        "                   factor=0.5,\n",
        "                   patience=1,\n",
        "                   verbose=False, \n",
        "                   threshold=0.0001,\n",
        "                   threshold_mode='abs',\n",
        "                   cooldown=0, \n",
        "                   min_lr=1e-8,\n",
        "                   eps=1e-08\n",
        "                )] * N_EXPERIMENTS\n",
        "#LR_PARAMS = [dict(T_max=10)] * N_EXPERIMENTS\n",
        "\n",
        "# HALF PRECISION\n",
        "HP = [False] * N_EXPERIMENTS\n",
        "\n",
        "# GLOBAL PARAMETERS\n",
        "EPOCHS=45\n",
        "N_CLASSES = 264\n",
        "DISPLAY_PLOT=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhKaxmyev1kL",
        "colab_type": "text"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5e8mXKQxYuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(N_EXPERIMENTS):\n",
        "    # DISPLAY FOLD INFO\n",
        "    if DEVICE=='TPU':\n",
        "        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\n",
        "    print('#'*25); print('#### FOLD',fold+1)\n",
        "    print('#### Image Size %i with EfficientNet B%i and batch_size %i'%\n",
        "          (IMG_SIZES[fold], EFF_NETS[fold], BATCH_SIZES[fold]*REPLICAS))\n",
        "    \n",
        "    # CREATE TRAIN AND VALIDATION SUBSETS\n",
        "    files_train, files_val = get_fold(i, files_fold)\n",
        "    \n",
        "    # BUILD MODEL\n",
        "    print(f\"Building model {fold}\")\n",
        "    K.clear_session()\n",
        "    with strategy.scope():\n",
        "        model = get_model(MODEL[fold],264)\n",
        "\n",
        "    # SAVE BEST MODEL EACH FOLD\n",
        "    sv = tf.keras.callbacks.ModelCheckpoint('/content/drive/My Drive/Kaggle/melanoma_model5_extra_malign/'+'fold-%i.h5'%fold, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min', save_freq='epoch')\n",
        "    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "   \n",
        "    # TRAIN\n",
        "    print('Training...')\n",
        "    history = model.fit(\n",
        "        load_dataset(files_train, batch_size=BATCH_SIZES[fold], labeled=True, ordered=False, melspectrogram_parameters=MELSPECTOGRAM_PARAMS[i]),\n",
        "        epochs = EPOCHS[fold], \n",
        "        callbacks = [es,sv,get_lr_callback(BATCH_SIZES[fold])], \n",
        "        steps_per_epoch = count_data_items(files_train)/BATCH_SIZES[fold]//REPLICAS,\n",
        "        validation_data = load_dataset(files_val, batch_size=BATCH_SIZES[fold], labeled=True, ordered=False, melspectrogram_parameters=MELSPECTOGRAM_PARAMS[i]),\n",
        "        #class_weight = {0:1,1:10},\n",
        "        verbose = VERBOSE\n",
        "    )\n",
        "\n",
        "    # PLOT TRAINING\n",
        "    if DISPLAY_PLOT:\n",
        "        plt.figure(figsize=(15,5))\n",
        "        plt.plot(np.arange(len(history.history)), history.history['train'],'-o',label='Train Loss',color='#ff7f0e')\n",
        "        plt.plot(np.arange(len(history.history)), history.history['val'],'-o',label='Val Loss',color='#1f77b4')\n",
        "        x = np.argmin( history['val'] ); y = np.min( history['val'] )\n",
        "        xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n",
        "        plt.text(x-0.03*xdist,y-0.13*ydist,'min loss\\n%.2f'%y,size=14)\n",
        "        plt.ylabel('Loss',size=14); plt.xlabel('Epoch',size=14)\n",
        "        plt.legend(loc=2)\n",
        "        \n",
        "        plt2 = plt.gca().twinx()\n",
        "        plt2.plot(np.arange(len(history.history)),history.history['lr'],'-o',label='LR',color='#2ca02c')\n",
        "        plt.ylabel('LR',size=14)\n",
        "        \n",
        "        plt.title('Experiment %i'%i,size=18)\n",
        "        plt.legend(loc=3)\n",
        "        plt.show()\n",
        "    \n",
        "    print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}