{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "4features-pseudolabelling2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benayas1/ALV_Framework/blob/master/covid/4features_pseudolabelling2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw6wMddHiuQa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5629c887-c36b-47ff-9a2a-066cf88b37f2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mzds6-Htiw4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#the basics\n",
        "import pandas as pd, numpy as np\n",
        "import math, json, gc, random, os, sys\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "#tensorflow deep learning basics\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow.keras.layers as L\n",
        "\n",
        "import time\n",
        "\n",
        "#for model evaluation\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "\n",
        "ROOT = '/content/drive/My Drive/Kaggle/covid/'\n",
        "PATH = '4sequences-pseudolabelling2/'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o31ocX-jEot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "   \n",
        "def adjust(public_df, private_df, public_pred, private_pred):\n",
        "    predictions = []\n",
        "\n",
        "    for df, preds in [(public_df, public_pred), (private_df, private_pred)]:\n",
        "        for i, uid in enumerate(df.id):\n",
        "            single_pred = preds[i]\n",
        "\n",
        "            single_df = pd.DataFrame(single_pred, columns=target_cols)\n",
        "            single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
        "\n",
        "            predictions.append(single_df)\n",
        "\n",
        "    preds_df = pd.concat(predictions)\n",
        "    return preds_df\n",
        "    \n",
        "def blend_column(dfs, weights, column):\n",
        "    values = np.array([df[column]*w for df, w in list(zip(dfs, weights))])\n",
        "    values = np.sum(values, axis=0)\n",
        "    return values\n",
        "\n",
        "def get_fold(fold, folds):\n",
        "    train_idx = np.concatenate([folds[i] for i in range(len(folds)) if i != fold])\n",
        "    val_idx = folds[fold]\n",
        "    return train_idx, val_idx\n",
        "\n",
        "def preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type'], map_tokens=None):\n",
        "    return np.transpose(\n",
        "        np.array(\n",
        "            df[cols]\n",
        "            .applymap(lambda seq: [map_tokens[x] for x in seq])\n",
        "            .values\n",
        "            .tolist()\n",
        "        ),\n",
        "        (0, 2, 1)\n",
        "    )\n",
        "\n",
        "def load_predict(model, path, public_inputs, private_inputs):\n",
        "    short = build_model(model, seq_len=107, pred_len=107)\n",
        "    short.load_weights(path)\n",
        "    long =  build_model(model, seq_len=130, pred_len=130)\n",
        "    long.load_weights(path)\n",
        "    public = short.predict(public_inputs)\n",
        "    private = long.predict(private_inputs)\n",
        "    return public, private\n",
        "\n",
        "def MCRMSE(y_true, y_pred):\n",
        "    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
        "    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)\n",
        "\n",
        "def pairs(seq, structure):\n",
        "    pairs = seq.copy()\n",
        "    stack = []\n",
        "    for i,s in enumerate(structure):\n",
        "        if s == '(':\n",
        "            stack.append((i,seq[i]))\n",
        "        if s == ')':\n",
        "            pos, pair = stack.pop()\n",
        "            pairs[pos] = seq[i]\n",
        "            pairs[i] = pair\n",
        "    return pairs\n",
        "\n",
        "def add_labels_test(path, test_df, target_cols):\n",
        "    pseudo_labelled = pd.read_csv(path)\n",
        "    pseudo_labelled['id']  = pseudo_labelled['id_seqpos'].apply(lambda x: '_'.join(x.split('_')[:2]))\n",
        "    pseudo_labelled['idx'] = pseudo_labelled['id_seqpos'].apply(lambda x: int(x.split('_')[2]))\n",
        "    pseudo_labelled = pseudo_labelled[pseudo_labelled['idx']<68]\n",
        "    \n",
        "    test_labels = []\n",
        "    for id, g in pseudo_labelled.groupby('id'):\n",
        "        sample = {'id': id}\n",
        "        for c in target_cols:\n",
        "            sample[c] = g[c].values\n",
        "        test_labels.append(sample)\n",
        "    test_labels = pd.DataFrame(test_labels)\n",
        "    \n",
        "    df = test_df.merge(test_labels, on='id', how='left')\n",
        "    return df\n",
        "\n",
        "def trim_sequences(df, cols, length=107):\n",
        "    for c in cols:\n",
        "        df[c] = df[c].apply(lambda x: x[:length])\n",
        "    return df"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIbfJSGDipPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Seed\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    \n",
        "SEED=42\n",
        "seed_everything(SEED)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ML8wFtCipPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get comp data\n",
        "train = pd.read_json(ROOT+'train.json', lines=True)\n",
        "test = pd.read_json(ROOT+'test.json', lines=True)\n",
        "sample_sub = pd.read_csv(ROOT+'sample_submission.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9avOBeiDipPZ",
        "colab_type": "text"
      },
      "source": [
        "# Brief EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPdPDGQ0ipPZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "64105fb3-00a7-463e-f4c1-f879b9bd1774"
      },
      "source": [
        "train['pairs'] = train.apply(lambda x: pairs(list(x['sequence']), list(x['structure'])), axis=1)\n",
        "test['pairs'] = test.apply(lambda x: pairs(list(x['sequence']), list(x['structure'])), axis=1)\n",
        "print(train.shape)\n",
        "if ~ train.isnull().values.any(): print('No missing values')\n",
        "print(test.shape)\n",
        "if ~ test.isnull().values.any(): print('No missing values')\n",
        "print(sample_sub.shape)\n",
        "if ~ sample_sub.isnull().values.any(): print('No missing values')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2400, 20)\n",
            "No missing values\n",
            "(3634, 8)\n",
            "No missing values\n",
            "(457953, 6)\n",
            "No missing values\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOpVL18QipPe",
        "colab_type": "text"
      },
      "source": [
        "# Processing\n",
        "\n",
        "**From the data [description tab](https://www.kaggle.com/c/stanford-covid-vaccine/data), we must predict multiple ground truths in this competition, 5 to be exact. While the submission requires all 5, only 3 are scored: `reactivity`, `deg_Mg_pH10` and `deg_Mg_50C`**\n",
        "\n",
        "**The training features we are given are as follows:**\n",
        "\n",
        "* **id** - An arbitrary identifier for each sample.\n",
        "* **seq_scored** - (68 in Train and Public Test, 91 in Private Test) Integer value denoting the number of positions used in scoring with predicted values. This should match the length of `reactivity`, `deg_*` and `*_error_*` columns. Note that molecules used for the Private Test will be longer than those in the Train and Public Test data, so the size of this vector will be different.\n",
        "* **seq_length** - (107 in Train and Public Test, 130 in Private Test) Integer values, denotes the length of `sequence`. Note that molecules used for the Private Test will be longer than those in the Train and Public Test data, so the size of this vector will be different.\n",
        "* **sequence** - (1x107 string in Train and Public Test, 130 in Private Test) Describes the RNA sequence, a combination of `A`, `G`, `U`, and `C` for each sample. Should be 107 characters long, and the first 68 bases should correspond to the 68 positions specified in `seq_scored` (note: indexed starting at 0).\n",
        "* **structure** - (1x107 string in Train and Public Test, 130 in Private Test) An array of `(`, `)`, and `.` characters that describe whether a base is estimated to be paired or unpaired. Paired bases are denoted by opening and closing parentheses e.g. (....) means that base 0 is paired to base 5, and bases 1-4 are unpaired.\n",
        "* **reactivity** - (1x68 vector in Train and Public Test, 1x91 in Private Test) An array of floating point numbers, should have the same length as `seq_scored`. These numbers are reactivity values for the first 68 bases as denoted in `sequence`, and used to determine the likely secondary structure of the RNA sample.\n",
        "* **deg_pH10** - (1x68 vector in Train and Public Test, 1x91 in Private Test) An array of floating point numbers, should have the same length as `seq_scored`. These numbers are reactivity values for the first 68 bases as denoted in `sequence`, and used to determine the likelihood of degradation at the base/linkage after incubating without magnesium at high pH (pH 10).\n",
        "* **deg_Mg_pH10** - (1x68 vector in Train and Public Test, 1x91 in Private Test) An array of floating point numbers, should have the same length as `seq_scored`. These numbers are reactivity values for the first 68 bases as denoted in `sequence`, and used to determine the likelihood of degradation at the base/linkage after incubating with magnesium in high pH (pH 10).\n",
        "* **deg_50C** - (1x68 vector in Train and Public Test, 1x91 in Private Test) An array of floating point numbers, should have the same length as `seq_scored`. These numbers are reactivity values for the first 68 bases as denoted in `sequence`, and used to determine the likelihood of degradation at the base/linkage after incubating without magnesium at high temperature (50 degrees Celsius).\n",
        "* **deg_Mg_50C** - (1x68 vector in Train and Public Test, 1x91 in Private Test) An array of floating point numbers, should have the same length as `seq_scored`. These numbers are reactivity values for the first 68 bases as denoted in `sequence`, and used to determine the likelihood of degradation at the base/linkage after incubating with magnesium at high temperature (50 degrees Celsius).\n",
        "* **`*_error_*`** - An array of floating point numbers, should have the same length as the corresponding `reactivity` or `deg_*` columns, calculated errors in experimental values obtained in `reactivity` and `deg_*` columns.\n",
        "* **predicted_loop_type** - (1x107 string) Describes the structural context (also referred to as 'loop type')of each character in `sequence`. Loop types assigned by bpRNA from Vienna RNAfold 2 structure. From the bpRNA_documentation: S: paired \"Stem\" M: Multiloop I: Internal loop B: Bulge H: Hairpin loop E: dangling End X: eXternal loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJYOsGVtipPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#target columns\n",
        "target_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n",
        "cols = ['sequence', 'structure', 'predicted_loop_type', 'pairs']\n",
        "token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7pFs1teipPj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e9dc36f-4de4-468a-f66a-386be95002da"
      },
      "source": [
        "train = train[train.signal_to_noise > 1]  # some signals have a lot of noise\n",
        "train_inputs = preprocess_inputs(train, cols=['sequence', 'structure', 'predicted_loop_type', 'pairs'], map_tokens=token2int)\n",
        "train_labels = np.array(train[target_cols].values.tolist()).transpose((0, 2, 1))\n",
        "print('Train Input shape', train_inputs.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Input shape (2096, 107, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpcI5XkGipPp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a2c8f18-f9ad-4b8f-bada-116751aa6a7d"
      },
      "source": [
        "test = trim_sequences(test, cols, 107)\n",
        "test = add_labels_test(ROOT+'submission_4features_25623.csv', test, target_cols)\n",
        "test_inputs = preprocess_inputs(test, cols=['sequence', 'structure', 'predicted_loop_type', 'pairs'], map_tokens=token2int)\n",
        "test_labels = np.array(test[target_cols].values.tolist()).transpose((0, 2, 1))\n",
        "print('Test Input shape', test_inputs.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Input shape (3634, 107, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrFM-Y7QipPv",
        "colab_type": "text"
      },
      "source": [
        "# Model\n",
        "\n",
        "**We begin with a simple GRU model taken from the one and only [Xhlulu](https://www.kaggle.com/xhlulu)'s notebook [here](https://www.kaggle.com/xhlulu/openvaccine-simple-gru-model)**\n",
        "\n",
        "**From the documentation of this competition, you can read that due to technical reasons, measurements cannot be carried out on the final bases of the RNA sequences we have just have experimental data (as ground truths) in 5 conditions for the first 68 bases. This means we must truncate the output of our model:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1Qy2NmwipPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gru_layer(hidden_dim, dropout):\n",
        "    return tf.keras.layers.Bidirectional(\n",
        "                                tf.keras.layers.GRU(hidden_dim,\n",
        "                                dropout=dropout,\n",
        "                                return_sequences=True,\n",
        "                                kernel_initializer = 'orthogonal'))\n",
        "\n",
        "def lstm_layer(hidden_dim, dropout):\n",
        "    return tf.keras.layers.Bidirectional(\n",
        "                                tf.keras.layers.LSTM(hidden_dim,\n",
        "                                dropout=dropout,\n",
        "                                return_sequences=True,\n",
        "                                kernel_initializer = 'orthogonal'))\n",
        "\n",
        "def build_model(model,seq_len=107, pred_len=68, dropout=0.5,\n",
        "                embed_dim=75, hidden_dim=192, n_sequences=4):\n",
        "    \n",
        "    inputs = tf.keras.layers.Input(shape=(seq_len, n_sequences))\n",
        "\n",
        "    embed = tf.keras.layers.Embedding(input_dim=len(token2int), output_dim=embed_dim)(inputs)\n",
        "    reshaped = tf.reshape(embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3]))\n",
        "    \n",
        "    reshaped = tf.keras.layers.SpatialDropout1D(.2)(reshaped)\n",
        "    \n",
        "    if model == 0:\n",
        "        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "        \n",
        "    if model == 1:\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
        "        \n",
        "    if model == 2:\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
        "        \n",
        "    if model == 3:\n",
        "        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "    \n",
        "    #only making predictions on the first part of each sequence\n",
        "    truncated = hidden[:, :pred_len]\n",
        "    \n",
        "    out = tf.keras.layers.Dense(5, activation='linear')(truncated)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=out)\n",
        "\n",
        "    #some optimizers\n",
        "    adam = tf.optimizers.Adam()\n",
        "    radam = tfa.optimizers.RectifiedAdam()\n",
        "    lookahead = tfa.optimizers.Lookahead(adam, sync_period=6)\n",
        "    ranger = tfa.optimizers.Lookahead(radam, sync_period=6)\n",
        "    \n",
        "    model.compile(optimizer = adam, loss=MCRMSE)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUleRiRmipPz",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "\n",
        "**Create train/val split now so both models are trained and evaluated on the same samples:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nI0H_MxipP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = KFold(5, shuffle=True, random_state=SEED)\n",
        "folds = {}\n",
        "for i, (train_index, val_index) in enumerate(cv.split(train_inputs)):\n",
        "    folds[i] = val_index\n",
        "    \n",
        "def get_fold(fold, folds):\n",
        "    train_idx = np.concatenate([folds[i] for i in range(len(folds)) if i != fold])\n",
        "    val_idx = folds[fold]\n",
        "    return train_idx, val_idx"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WEmrITiipP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_inputs, val_inputs, train_labels, val_labels = train_test_split(train_inputs, train_labels, test_size=.01, random_state=34)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA5dWpx6ipP_",
        "colab_type": "text"
      },
      "source": [
        "**We will use a simple learning rate callback for now:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME1ns04FipQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_callback = tf.keras.callbacks.ReduceLROnPlateau()\n",
        "#lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=2, mode='min', min_delta=0.00001, cooldown=0, min_lr=1e-8)\n",
        "#lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=6, verbose=2, mode='min', min_delta=0.001, cooldown=0, min_lr=1e-8)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9a89dNqipQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(model_data, X, y, X_test, y_test, epochs=150, batch_size=64, verbose=0, patience=13, folds=None):\n",
        "    \n",
        "    paths = []\n",
        "    errors = []\n",
        "    for i in range(len(folds)):\n",
        "        start = time.time()\n",
        "        print('Training fold',i)\n",
        "        train_idx, val_idx = get_fold(i, folds)\n",
        "        \n",
        "        X_train, y_train = X[train_idx], y[train_idx]\n",
        "        X_val, y_val = X[val_idx], y[val_idx]\n",
        "        \n",
        "        # Adding psudo labelling\n",
        "        #X_train, y_train = np.concatenate([X_train, X_test]), np.concatenate([y_train, y_test])\n",
        "        \n",
        "        gru = build_model(model=model_data[0])\n",
        "        path = model_data[1]+'_fold_'+str(i)+'.h5'\n",
        "        sv_gru = tf.keras.callbacks.ModelCheckpoint(path), verbose=1)\n",
        "        es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=patience)\n",
        "\n",
        "        history = gru.fit(\n",
        "            X_train, y_train, \n",
        "            validation_data=(X_val, y_val),\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            callbacks=[lr_callback, sv_gru, es],\n",
        "            verbose = verbose\n",
        "        )\n",
        "        \n",
        "        best_epoch = np.argmin(history.history['val_loss'])\n",
        "        min_val_loss = history.history['val_loss'][best_epoch]\n",
        "        min_train_loss = history.history['loss'][best_epoch]\n",
        "        #paths.append(path)\n",
        "        #errors.append(min_val_loss)\n",
        "\n",
        "        print(f\"\\tMin training loss={min_train_loss}, min validation loss={min_val_loss}, elapsed {time.time()-start}\")\n",
        "\n",
        "        # Training on pseudolabelled dataset\n",
        "\n",
        "        gru.load_weights(path)\n",
        "        history = gru.fit(\n",
        "            X_test, y_test, \n",
        "            validation_data=(X_val, y_val),\n",
        "            batch_size=batch_size,\n",
        "            epochs=10,\n",
        "            callbacks=[lr_callback, es],\n",
        "            verbose = verbose\n",
        "        )\n",
        "        gru.save_weights(path)\n",
        "\n",
        "        best_epoch = np.argmin(history.history['val_loss'])\n",
        "        min_val_loss = history.history['val_loss'][best_epoch]\n",
        "        min_train_loss = history.history['loss'][best_epoch]\n",
        "        paths.append(path)\n",
        "        errors.append(min_val_loss)\n",
        "\n",
        "        print(f\"\\tLabelled: Min training loss={min_train_loss}, min validation loss={min_val_loss}, elapsed {time.time()-start}\")\n",
        "        \n",
        "    print(f\"\\tOOF CV loss={np.mean(errors)}\")\n",
        "    return list(zip([model_data[0]]*len(paths) , paths)), errors"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwkmL4pnipQG",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFc59pDlipQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_results = []\n",
        "errors = []\n",
        "model_data = [(0,ROOT+PATH+'model0'), (1,ROOT+PATH+'model1'), (2,ROOT+PATH+'model2'), (3,ROOT+PATH+'model3')]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNAdF_0WipQK",
        "colab_type": "text"
      },
      "source": [
        "### 1. GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqIz4f06ipQL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c3077d72-c944-47db-eee3-8f1a0bccbc4d"
      },
      "source": [
        "res, error = fit(model_data[0], train_inputs, train_labels, test_inputs, test_labels, batch_size=16, verbose=2, patience=10, folds=folds)\n",
        "model_results += res\n",
        "errors += error"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training fold 0\n",
            "Epoch 1/150\n",
            "105/105 - 7s - loss: 0.4079 - val_loss: 0.3639\n",
            "Epoch 2/150\n",
            "105/105 - 5s - loss: 0.3588 - val_loss: 0.3494\n",
            "Epoch 3/150\n",
            "105/105 - 5s - loss: 0.3402 - val_loss: 0.3295\n",
            "Epoch 4/150\n",
            "105/105 - 5s - loss: 0.3276 - val_loss: 0.3214\n",
            "Epoch 5/150\n",
            "105/105 - 5s - loss: 0.3145 - val_loss: 0.3047\n",
            "Epoch 6/150\n",
            "105/105 - 5s - loss: 0.3017 - val_loss: 0.2881\n",
            "Epoch 7/150\n",
            "105/105 - 5s - loss: 0.2933 - val_loss: 0.2807\n",
            "Epoch 8/150\n",
            "105/105 - 5s - loss: 0.2832 - val_loss: 0.2697\n",
            "Epoch 9/150\n",
            "105/105 - 5s - loss: 0.2737 - val_loss: 0.2627\n",
            "Epoch 10/150\n",
            "105/105 - 5s - loss: 0.2668 - val_loss: 0.2570\n",
            "Epoch 11/150\n",
            "105/105 - 5s - loss: 0.2622 - val_loss: 0.2499\n",
            "Epoch 12/150\n",
            "105/105 - 5s - loss: 0.2579 - val_loss: 0.2462\n",
            "Epoch 13/150\n",
            "105/105 - 5s - loss: 0.2521 - val_loss: 0.2400\n",
            "Epoch 14/150\n",
            "105/105 - 5s - loss: 0.2489 - val_loss: 0.2425\n",
            "Epoch 15/150\n",
            "105/105 - 5s - loss: 0.2440 - val_loss: 0.2386\n",
            "Epoch 16/150\n",
            "105/105 - 5s - loss: 0.2410 - val_loss: 0.2373\n",
            "Epoch 17/150\n",
            "105/105 - 5s - loss: 0.2370 - val_loss: 0.2345\n",
            "Epoch 18/150\n",
            "105/105 - 5s - loss: 0.2365 - val_loss: 0.2393\n",
            "Epoch 19/150\n",
            "105/105 - 5s - loss: 0.2321 - val_loss: 0.2331\n",
            "Epoch 20/150\n",
            "105/105 - 5s - loss: 0.2295 - val_loss: 0.2294\n",
            "Epoch 21/150\n",
            "105/105 - 5s - loss: 0.2276 - val_loss: 0.2319\n",
            "Epoch 22/150\n",
            "105/105 - 5s - loss: 0.2252 - val_loss: 0.2388\n",
            "Epoch 23/150\n",
            "105/105 - 5s - loss: 0.2221 - val_loss: 0.2291\n",
            "Epoch 24/150\n",
            "105/105 - 5s - loss: 0.2188 - val_loss: 0.2297\n",
            "Epoch 25/150\n",
            "105/105 - 5s - loss: 0.2175 - val_loss: 0.2337\n",
            "Epoch 26/150\n",
            "105/105 - 5s - loss: 0.2162 - val_loss: 0.2293\n",
            "Epoch 27/150\n",
            "105/105 - 5s - loss: 0.2141 - val_loss: 0.2261\n",
            "Epoch 28/150\n",
            "105/105 - 5s - loss: 0.2121 - val_loss: 0.2263\n",
            "Epoch 29/150\n",
            "105/105 - 5s - loss: 0.2105 - val_loss: 0.2253\n",
            "Epoch 30/150\n",
            "105/105 - 5s - loss: 0.2084 - val_loss: 0.2258\n",
            "Epoch 31/150\n",
            "105/105 - 5s - loss: 0.2071 - val_loss: 0.2247\n",
            "Epoch 32/150\n",
            "105/105 - 5s - loss: 0.2053 - val_loss: 0.2270\n",
            "Epoch 33/150\n",
            "105/105 - 5s - loss: 0.2043 - val_loss: 0.2241\n",
            "Epoch 34/150\n",
            "105/105 - 5s - loss: 0.2030 - val_loss: 0.2229\n",
            "Epoch 35/150\n",
            "105/105 - 5s - loss: 0.2015 - val_loss: 0.2249\n",
            "Epoch 36/150\n",
            "105/105 - 5s - loss: 0.2004 - val_loss: 0.2236\n",
            "Epoch 37/150\n",
            "105/105 - 5s - loss: 0.1993 - val_loss: 0.2210\n",
            "Epoch 38/150\n",
            "105/105 - 5s - loss: 0.1976 - val_loss: 0.2229\n",
            "Epoch 39/150\n",
            "105/105 - 5s - loss: 0.1964 - val_loss: 0.2228\n",
            "Epoch 40/150\n",
            "105/105 - 5s - loss: 0.1951 - val_loss: 0.2262\n",
            "Epoch 41/150\n",
            "105/105 - 5s - loss: 0.1953 - val_loss: 0.2237\n",
            "Epoch 42/150\n",
            "105/105 - 5s - loss: 0.1936 - val_loss: 0.2234\n",
            "Epoch 43/150\n",
            "105/105 - 5s - loss: 0.1931 - val_loss: 0.2240\n",
            "Epoch 44/150\n",
            "105/105 - 5s - loss: 0.1918 - val_loss: 0.2248\n",
            "Epoch 45/150\n",
            "105/105 - 5s - loss: 0.1904 - val_loss: 0.2218\n",
            "Epoch 46/150\n",
            "105/105 - 5s - loss: 0.1897 - val_loss: 0.2218\n",
            "Epoch 47/150\n",
            "105/105 - 5s - loss: 0.1892 - val_loss: 0.2207\n",
            "Epoch 48/150\n",
            "105/105 - 5s - loss: 0.1881 - val_loss: 0.2218\n",
            "Epoch 49/150\n",
            "105/105 - 5s - loss: 0.1878 - val_loss: 0.2195\n",
            "Epoch 50/150\n",
            "105/105 - 5s - loss: 0.1870 - val_loss: 0.2207\n",
            "Epoch 51/150\n",
            "105/105 - 5s - loss: 0.1862 - val_loss: 0.2202\n",
            "Epoch 52/150\n",
            "105/105 - 5s - loss: 0.1852 - val_loss: 0.2192\n",
            "Epoch 53/150\n",
            "105/105 - 5s - loss: 0.1848 - val_loss: 0.2221\n",
            "Epoch 54/150\n",
            "105/105 - 5s - loss: 0.1846 - val_loss: 0.2218\n",
            "Epoch 55/150\n",
            "105/105 - 5s - loss: 0.1831 - val_loss: 0.2234\n",
            "Epoch 56/150\n",
            "105/105 - 5s - loss: 0.1824 - val_loss: 0.2201\n",
            "Epoch 57/150\n",
            "105/105 - 5s - loss: 0.1823 - val_loss: 0.2210\n",
            "Epoch 58/150\n",
            "105/105 - 5s - loss: 0.1818 - val_loss: 0.2195\n",
            "Epoch 59/150\n",
            "105/105 - 5s - loss: 0.1803 - val_loss: 0.2184\n",
            "Epoch 60/150\n",
            "105/105 - 5s - loss: 0.1798 - val_loss: 0.2209\n",
            "Epoch 61/150\n",
            "105/105 - 5s - loss: 0.1795 - val_loss: 0.2188\n",
            "Epoch 62/150\n",
            "105/105 - 5s - loss: 0.1791 - val_loss: 0.2189\n",
            "Epoch 63/150\n",
            "105/105 - 5s - loss: 0.1782 - val_loss: 0.2203\n",
            "Epoch 64/150\n",
            "105/105 - 5s - loss: 0.1778 - val_loss: 0.2226\n",
            "Epoch 65/150\n",
            "105/105 - 5s - loss: 0.1774 - val_loss: 0.2208\n",
            "Epoch 66/150\n",
            "105/105 - 5s - loss: 0.1767 - val_loss: 0.2191\n",
            "Epoch 67/150\n",
            "105/105 - 5s - loss: 0.1760 - val_loss: 0.2184\n",
            "Epoch 68/150\n",
            "105/105 - 5s - loss: 0.1756 - val_loss: 0.2205\n",
            "Epoch 69/150\n",
            "105/105 - 5s - loss: 0.1749 - val_loss: 0.2221\n",
            "Epoch 70/150\n",
            "105/105 - 5s - loss: 0.1699 - val_loss: 0.2164\n",
            "Epoch 71/150\n",
            "105/105 - 5s - loss: 0.1680 - val_loss: 0.2161\n",
            "Epoch 72/150\n",
            "105/105 - 5s - loss: 0.1666 - val_loss: 0.2156\n",
            "Epoch 73/150\n",
            "105/105 - 5s - loss: 0.1664 - val_loss: 0.2158\n",
            "Epoch 74/150\n",
            "105/105 - 5s - loss: 0.1659 - val_loss: 0.2160\n",
            "Epoch 75/150\n",
            "105/105 - 5s - loss: 0.1651 - val_loss: 0.2152\n",
            "Epoch 76/150\n",
            "105/105 - 5s - loss: 0.1648 - val_loss: 0.2151\n",
            "Epoch 77/150\n",
            "105/105 - 5s - loss: 0.1648 - val_loss: 0.2147\n",
            "Epoch 78/150\n",
            "105/105 - 5s - loss: 0.1644 - val_loss: 0.2150\n",
            "Epoch 79/150\n",
            "105/105 - 5s - loss: 0.1641 - val_loss: 0.2150\n",
            "Epoch 80/150\n",
            "105/105 - 5s - loss: 0.1640 - val_loss: 0.2151\n",
            "Epoch 81/150\n",
            "105/105 - 5s - loss: 0.1635 - val_loss: 0.2151\n",
            "Epoch 82/150\n",
            "105/105 - 5s - loss: 0.1634 - val_loss: 0.2156\n",
            "Epoch 83/150\n",
            "105/105 - 5s - loss: 0.1634 - val_loss: 0.2152\n",
            "Epoch 84/150\n",
            "105/105 - 5s - loss: 0.1632 - val_loss: 0.2151\n",
            "Epoch 85/150\n",
            "105/105 - 5s - loss: 0.1627 - val_loss: 0.2150\n",
            "Epoch 86/150\n",
            "105/105 - 5s - loss: 0.1623 - val_loss: 0.2150\n",
            "Epoch 87/150\n",
            "105/105 - 5s - loss: 0.1625 - val_loss: 0.2150\n",
            "\tMin training loss=0.16477183997631073, min validation loss=0.21467706561088562, elapsed 444.73897886276245\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-f469835aac09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_results\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-20783218f30c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model_data, X, y, X_test, y_test, epochs, batch_size, verbose, patience, folds)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Training on pseudolabelled dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mgru\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         history = gru.fit(\n\u001b[1;32m     42\u001b[0m             \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2202\u001b[0m           'first, then load the weights.')\n\u001b[1;32m   2203\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2204\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2205\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2206\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/content/drive/My Drive/Kaggle/covid/4sequences-pseudolabelling2/model0_fold_0.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS6GDoW1ipQR",
        "colab_type": "text"
      },
      "source": [
        "### 2. LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruWJNYFJipQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res, error = fit(model_data[1], train_inputs, train_labels, test_inputs, test_labels, batch_size=16,verbose=0, patience=10, folds=folds)\n",
        "model_results += res\n",
        "errors += error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYNg6dm9ipQa",
        "colab_type": "text"
      },
      "source": [
        "### 3. LSTM + GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KWMJiqfipQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res, error = fit(model_data[2], train_inputs, train_labels, test_inputs, test_labels, batch_size=16,verbose=0, folds=folds)\n",
        "model_results += res\n",
        "errors += error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQvEELBeipQk",
        "colab_type": "text"
      },
      "source": [
        "### 4. GRU + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWDA4JVZipQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res, error = fit(model_data[3], train_inputs, train_labels, test_inputs, test_labels, batch_size=16,verbose=0, folds=folds)\n",
        "model_results += res\n",
        "errors += error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzF5iiNPipQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('CV error is ', np.mean(errors))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQJa4kMwipQu",
        "colab_type": "text"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuGqJ-quipQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "public_df = test.query(\"seq_length == 107\").copy()\n",
        "private_df = test.query(\"seq_length == 130\").copy()\n",
        "\n",
        "public_inputs = preprocess_inputs(public_df)\n",
        "private_inputs = preprocess_inputs(private_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoZ3AGkeipQ2",
        "colab_type": "text"
      },
      "source": [
        "**Predict twice, one for the public leaderboard, the other for the private leaderboard:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA0bqVgzipQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_trained_models(model, path):\n",
        "    short = build_model(model, seq_len=107, pred_len=107)\n",
        "    short.load_weights(path)\n",
        "    long =  build_model(model, seq_len=130, pred_len=130)\n",
        "    long.load_weights(path)\n",
        "    return predict_pair(short, long)\n",
        "    #return short, long\n",
        "\n",
        "def predict_pair(short, long):\n",
        "    public = short.predict(public_inputs)\n",
        "    private = long.predict(private_inputs)\n",
        "    return public, private"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8gDKFGWipQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_n(f):\n",
        "    if f[6:14]=='gru_lstm': return 3\n",
        "    if f[6:14]=='lstm_gru': return 2\n",
        "    if f[6:10]=='lstm': return 1\n",
        "    if f[6:9]=='gru': return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mnv8F29ipRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from glob import glob\n",
        "model_results = glob('*.h5')\n",
        "model_results = [( get_n(f), f) for f in model_results]\n",
        "model_results = [(n, f) for n,f in model_results if n==3]\n",
        "model_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hety3iEFipRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#build all models\n",
        "#models = [load_trained_models(m,p) for m,p in tqdm(model_results) ]\n",
        "\n",
        "#and predict\n",
        "#predictions = [predict_pair(short, long) for short, long in tqdm(models)]\n",
        "predictions = [load_trained_models(m,p) for m,p in tqdm(model_results) ]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iKzKBQjipRN",
        "colab_type": "text"
      },
      "source": [
        "# Postprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3zcmqLgipRO",
        "colab_type": "text"
      },
      "source": [
        "### Adjust Output\n",
        "According to pubic and private test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJok2GQgipRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adjust(public_df, private_df, public_pred, private_pred):\n",
        "    predictions = []\n",
        "\n",
        "    for df, preds in [(public_df, public_pred), (private_df, private_pred)]:\n",
        "        for i, uid in enumerate(df.id):\n",
        "            single_pred = preds[i]\n",
        "\n",
        "            single_df = pd.DataFrame(single_pred, columns=target_cols)\n",
        "            single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
        "\n",
        "            predictions.append(single_df)\n",
        "\n",
        "    preds_df = pd.concat(predictions)\n",
        "    return preds_df\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgW1DrPtipRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfs  = [adjust(public_df, private_df, public_preds, private_preds) for public_preds, private_preds in tqdm(predictions)]\n",
        "weights = [1/len(dfs)] * len(dfs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1BXX8oKipRW",
        "colab_type": "text"
      },
      "source": [
        "### Blending"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewOX2dOPipRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def blend_column(dfs, weights, column):\n",
        "    values = np.array([df[column]*w for df, w in list(zip(dfs, weights))])\n",
        "    values = np.sum(values, axis=0)\n",
        "    return values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4102GachipRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "blend_preds_df = pd.DataFrame({'id_seqpos':dfs[0]['id_seqpos']})\n",
        "for c in target_cols:\n",
        "    blend_preds_df[c] = blend_column(dfs, weights, c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gJUp6LeipRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = sample_sub[['id_seqpos']].merge(blend_preds_df, on=['id_seqpos'])\n",
        "\n",
        "#sanity check\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF_Wb-2PipRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv('submission.csv', index=False)\n",
        "print('Submission saved')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhxwsCZdipRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}