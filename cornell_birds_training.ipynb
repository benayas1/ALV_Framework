{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "papermill": {
      "duration": 17359.838188,
      "end_time": "2020-08-21T21:37:49.849044",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2020-08-21T16:48:30.010856",
      "version": "2.1.0"
    },
    "colab": {
      "name": "cornell-birds-training.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benayas1/ALV_Framework/blob/master/cornell_birds_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.006096,
          "end_time": "2020-08-21T16:48:34.103941",
          "exception": false,
          "start_time": "2020-08-21T16:48:34.097845",
          "status": "completed"
        },
        "tags": [],
        "id": "6f_mMz3GsQuj",
        "colab_type": "text"
      },
      "source": [
        "# Training BirdSongs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "execution": {
          "iopub.execute_input": "2020-08-21T16:48:34.149928Z",
          "iopub.status.busy": "2020-08-21T16:48:34.143829Z",
          "iopub.status.idle": "2020-08-21T16:49:11.822933Z",
          "shell.execute_reply": "2020-08-21T16:49:11.821851Z"
        },
        "papermill": {
          "duration": 37.69724,
          "end_time": "2020-08-21T16:49:11.823059",
          "exception": false,
          "start_time": "2020-08-21T16:48:34.125819",
          "status": "completed"
        },
        "tags": [],
        "id": "geTlZ9vjsQuo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "acf3a3d2-ee1e-4acc-d272-747856e3b9bf"
      },
      "source": [
        "# Import apex for mixed precision training\n",
        "#!cd /kaggle/input/apexpytorch/ && pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./ >> /dev/null\n",
        "\n",
        "#!wget https://github.com/benayas1/benatools/archive/master.zip -P bena\n",
        "#!unzip bena/master.zip\n",
        "\n",
        "!pip install benatools >> /dev/null\n",
        "\n",
        "# Install resnest\n",
        "#!pip install ../input/resnest50-fast-package/resnest-0.0.6b20200701/resnest/ >> /dev/null\n",
        "!pip install soundfile\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from pathlib import Path\n",
        "import typing as tp\n",
        "import cv2\n",
        "import librosa\n",
        "import random\n",
        "import audioread\n",
        "import soundfile as sf\n",
        "import os\n",
        "import time as time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import benatools as bena\n",
        "from benatools.tools import MultiStratifiedKFold\n",
        "from benatools.torch.fitter import TorchFitter\n",
        "from benatools.torch.efficient_net import create_efn\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "\n",
        "!pip install gcsfs\n",
        "import gcsfs\n",
        "from google.colab import auth\n",
        "from google.cloud import storage\n",
        "\n",
        "\n",
        "#from apex import amp\n",
        "\n",
        "#import resnest.torch as resnest_torch\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "\n",
        "COLAB = True\n",
        "\n",
        "if COLAB:\n",
        "    os.environ.setdefault(\"GCLOUD_PROJECT\", \"omega-cosmos-116215\")\n",
        "    GS_BUCKET = 'benayas_kaggle'\n",
        "    !echo \"deb http://packages.cloud.google.com/apt gcsfuse-`lsb_release -c -s` main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list\n",
        "    !curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "    !sudo apt-get -y -q update\n",
        "    !sudo apt-get -y -q install gcsfuse\n",
        "    auth.authenticate_user()\n",
        "    !mkdir -p data\n",
        "    !gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 {GS_BUCKET} data\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.6/dist-packages (0.10.3.post1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (1.17.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.6/dist-packages (from gcsfs) (3.6.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from gcsfs) (4.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gcsfs) (2.23.0)\n",
            "Requirement already satisfied: fsspec>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (49.2.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.1.1)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (3.0.1)\n",
            "Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (1.1.0)\n",
            "Requirement already satisfied: multidict<5.0,>=4.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (4.7.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (19.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (3.7.4.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (1.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2020.6.20)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth>=1.2->gcsfs) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n",
            "deb http://packages.cloud.google.com/apt gcsfuse-bionic main\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   653  100   653    0     0  24185      0 --:--:-- --:--:-- --:--:-- 24185\n",
            "OK\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:2 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:5 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Hit:6 http://packages.cloud.google.com/apt gcsfuse-bionic InRelease\n",
            "Hit:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Ign:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Fetched 252 kB in 1s (324 kB/s)\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "gcsfuse is already the newest version (0.30.0).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 60 not upgraded.\n",
            "Using mount point: /content/data\n",
            "Opening GCS connection...\n",
            "Opening bucket...\n",
            "Mounting file system...\n",
            "daemonize.Run: readFromProcess: sub-process: mountWithArgs: mountWithConn: Mount: mount: running fusermount: exit status 1\n",
            "\n",
            "stderr:\n",
            "fusermount: mountpoint is not empty\n",
            "fusermount: if you are sure this is safe, use the 'nonempty' mount option\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-21T16:49:11.842194Z",
          "iopub.status.busy": "2020-08-21T16:49:11.841448Z",
          "iopub.status.idle": "2020-08-21T16:49:11.847344Z",
          "shell.execute_reply": "2020-08-21T16:49:11.846833Z"
        },
        "papermill": {
          "duration": 0.018968,
          "end_time": "2020-08-21T16:49:11.847439",
          "exception": false,
          "start_time": "2020-08-21T16:49:11.828471",
          "status": "completed"
        },
        "tags": [],
        "id": "zmbBSKUDsQus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Seed\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    \n",
        "seed_everything(42)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.004918,
          "end_time": "2020-08-21T16:49:11.857601",
          "exception": false,
          "start_time": "2020-08-21T16:49:11.852683",
          "status": "completed"
        },
        "tags": [],
        "id": "IBFVmIm8sQuv",
        "colab_type": "text"
      },
      "source": [
        "# Read Data\n",
        "Read data from resampled datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-21T16:49:11.877218Z",
          "iopub.status.busy": "2020-08-21T16:49:11.876416Z",
          "iopub.status.idle": "2020-08-21T16:49:12.195754Z",
          "shell.execute_reply": "2020-08-21T16:49:12.196270Z"
        },
        "papermill": {
          "duration": 0.333707,
          "end_time": "2020-08-21T16:49:12.196418",
          "exception": false,
          "start_time": "2020-08-21T16:49:11.862711",
          "status": "completed"
        },
        "tags": [],
        "id": "VacvvoFKsQuw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "27924087-b192-40cd-cec7-b293dd34650d"
      },
      "source": [
        "%%time\n",
        "\n",
        "def get_df_kaggle(TRAIN_RESAMPLED_AUDIO_DIRS, train_df):\n",
        "    print('Data will be loaded from Kaggle Platform')\n",
        "    tmp_list = []\n",
        "    for audio_d in TRAIN_RESAMPLED_AUDIO_DIRS:\n",
        "        if not audio_d.exists():\n",
        "            continue\n",
        "        for ebird_d in audio_d.iterdir():\n",
        "            if ebird_d.is_file():\n",
        "                continue\n",
        "            for wav_f in ebird_d.iterdir():\n",
        "                tmp_list.append([ebird_d.name, wav_f.name, wav_f.as_posix()])\n",
        "                \n",
        "    train_wav_path_exist = pd.DataFrame(tmp_list, columns=[\"ebird_code\", \"resampled_filename\", \"file_path\"])\n",
        "    del tmp_list\n",
        "    train_all = pd.merge(train, train_wav_path_exist, on=[\"ebird_code\", \"resampled_filename\"], how=\"inner\")\n",
        "\n",
        "    print(train.shape)\n",
        "    print(train_wav_path_exist.shape)\n",
        "    print(train_all.shape)\n",
        "    return train_all\n",
        "\n",
        "def get_df_colab(TRAIN_RESAMPLED_AUDIO_DIRS, train_df, client):\n",
        "    print('Data will be loaded from GCS')\n",
        "    tmp_list = []\n",
        "    for audio_d in TRAIN_RESAMPLED_AUDIO_DIRS:\n",
        "        for f in glob.iglob(audio_d+'/*'):\n",
        "            if f[-4:] == '.csv':\n",
        "                continue\n",
        "            for wav_f in glob.iglob(f+'/*.wav'):\n",
        "                tmp_list.append( [f[f.rfind('/')+1:], wav_f[wav_f.rfind('/')+1:], wav_f] )\n",
        "\n",
        "    train_wav_path_exist = pd.DataFrame(tmp_list, columns=[\"ebird_code\", \"resampled_filename\", \"file_path\"])\n",
        "    del tmp_list\n",
        "    train_all = pd.merge(train, train_wav_path_exist, on=[\"ebird_code\", \"resampled_filename\"], how=\"inner\")\n",
        "\n",
        "    print(train.shape)\n",
        "    print(train_wav_path_exist.shape)\n",
        "    print(train_all.shape)\n",
        "    return train_all\n",
        "\n",
        "if COLAB:\n",
        "    INPUT_ROOT  = \"/content/data/birdsong-recognition/\"\n",
        "    TRAIN_RESAMPLED_AUDIO_DIRS = [\n",
        "      INPUT_ROOT + \"birdsong-resampled-train-audio-{:0>2}\".format(i)  for i in range(5)\n",
        "    ]\n",
        "    train = pd.read_csv(TRAIN_RESAMPLED_AUDIO_DIRS[0] + \"/train_mod.csv\")\n",
        "    storage_client = storage.Client()\n",
        "    train_all = get_df_colab(TRAIN_RESAMPLED_AUDIO_DIRS, train, storage_client)\n",
        "else:\n",
        "    ROOT = Path.cwd().parent\n",
        "    INPUT_ROOT = ROOT / \"input\"\n",
        "    RAW_DATA = INPUT_ROOT / \"birdsong-recognition\"\n",
        "    TRAIN_AUDIO_DIR = RAW_DATA / \"train_audio\"\n",
        "    TRAIN_RESAMPLED_AUDIO_DIRS = [\n",
        "      INPUT_ROOT / \"birdsong-resampled-train-audio-{:0>2}\".format(i)  for i in range(5)\n",
        "    ]\n",
        "    TEST_AUDIO_DIR = RAW_DATA / \"test_audio\"\n",
        "\n",
        "    train = pd.read_csv(TRAIN_RESAMPLED_AUDIO_DIRS[0] / \"train_mod.csv\")\n",
        "    train_all = get_df_kaggle(TRAIN_RESAMPLED_AUDIO_DIRS, train)\n",
        "\n",
        "train_all.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data will be loaded from GCS\n",
            "(21375, 38)\n",
            "(21375, 3)\n",
            "(21375, 39)\n",
            "CPU times: user 416 ms, sys: 92.3 ms, total: 509 ms\n",
            "Wall time: 2min 44s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2020-08-21T16:49:13.366038Z",
          "iopub.status.busy": "2020-08-21T16:49:13.363577Z",
          "iopub.status.idle": "2020-08-21T16:49:13.403846Z",
          "shell.execute_reply": "2020-08-21T16:49:13.404671Z"
        },
        "papermill": {
          "duration": 0.070452,
          "end_time": "2020-08-21T16:49:13.404901",
          "exception": false,
          "start_time": "2020-08-21T16:49:13.334449",
          "status": "completed"
        },
        "tags": [],
        "id": "hDxhGxwhsQu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Coding the bird names\n",
        "\n",
        "BIRD_CODE = {\n",
        "    'aldfly': 0, 'ameavo': 1, 'amebit': 2, 'amecro': 3, 'amegfi': 4,\n",
        "    'amekes': 5, 'amepip': 6, 'amered': 7, 'amerob': 8, 'amewig': 9,\n",
        "    'amewoo': 10, 'amtspa': 11, 'annhum': 12, 'astfly': 13, 'baisan': 14,\n",
        "    'baleag': 15, 'balori': 16, 'banswa': 17, 'barswa': 18, 'bawwar': 19,\n",
        "    'belkin1': 20, 'belspa2': 21, 'bewwre': 22, 'bkbcuc': 23, 'bkbmag1': 24,\n",
        "    'bkbwar': 25, 'bkcchi': 26, 'bkchum': 27, 'bkhgro': 28, 'bkpwar': 29,\n",
        "    'bktspa': 30, 'blkpho': 31, 'blugrb1': 32, 'blujay': 33, 'bnhcow': 34,\n",
        "    'boboli': 35, 'bongul': 36, 'brdowl': 37, 'brebla': 38, 'brespa': 39,\n",
        "    'brncre': 40, 'brnthr': 41, 'brthum': 42, 'brwhaw': 43, 'btbwar': 44,\n",
        "    'btnwar': 45, 'btywar': 46, 'buffle': 47, 'buggna': 48, 'buhvir': 49,\n",
        "    'bulori': 50, 'bushti': 51, 'buwtea': 52, 'buwwar': 53, 'cacwre': 54,\n",
        "    'calgul': 55, 'calqua': 56, 'camwar': 57, 'cangoo': 58, 'canwar': 59,\n",
        "    'canwre': 60, 'carwre': 61, 'casfin': 62, 'caster1': 63, 'casvir': 64,\n",
        "    'cedwax': 65, 'chispa': 66, 'chiswi': 67, 'chswar': 68, 'chukar': 69,\n",
        "    'clanut': 70, 'cliswa': 71, 'comgol': 72, 'comgra': 73, 'comloo': 74,\n",
        "    'commer': 75, 'comnig': 76, 'comrav': 77, 'comred': 78, 'comter': 79,\n",
        "    'comyel': 80, 'coohaw': 81, 'coshum': 82, 'cowscj1': 83, 'daejun': 84,\n",
        "    'doccor': 85, 'dowwoo': 86, 'dusfly': 87, 'eargre': 88, 'easblu': 89,\n",
        "    'easkin': 90, 'easmea': 91, 'easpho': 92, 'eastow': 93, 'eawpew': 94,\n",
        "    'eucdov': 95, 'eursta': 96, 'evegro': 97, 'fiespa': 98, 'fiscro': 99,\n",
        "    'foxspa': 100, 'gadwal': 101, 'gcrfin': 102, 'gnttow': 103, 'gnwtea': 104,\n",
        "    'gockin': 105, 'gocspa': 106, 'goleag': 107, 'grbher3': 108, 'grcfly': 109,\n",
        "    'greegr': 110, 'greroa': 111, 'greyel': 112, 'grhowl': 113, 'grnher': 114,\n",
        "    'grtgra': 115, 'grycat': 116, 'gryfly': 117, 'haiwoo': 118, 'hamfly': 119,\n",
        "    'hergul': 120, 'herthr': 121, 'hoomer': 122, 'hoowar': 123, 'horgre': 124,\n",
        "    'horlar': 125, 'houfin': 126, 'houspa': 127, 'houwre': 128, 'indbun': 129,\n",
        "    'juntit1': 130, 'killde': 131, 'labwoo': 132, 'larspa': 133, 'lazbun': 134,\n",
        "    'leabit': 135, 'leafly': 136, 'leasan': 137, 'lecthr': 138, 'lesgol': 139,\n",
        "    'lesnig': 140, 'lesyel': 141, 'lewwoo': 142, 'linspa': 143, 'lobcur': 144,\n",
        "    'lobdow': 145, 'logshr': 146, 'lotduc': 147, 'louwat': 148, 'macwar': 149,\n",
        "    'magwar': 150, 'mallar3': 151, 'marwre': 152, 'merlin': 153, 'moublu': 154,\n",
        "    'mouchi': 155, 'moudov': 156, 'norcar': 157, 'norfli': 158, 'norhar2': 159,\n",
        "    'normoc': 160, 'norpar': 161, 'norpin': 162, 'norsho': 163, 'norwat': 164,\n",
        "    'nrwswa': 165, 'nutwoo': 166, 'olsfly': 167, 'orcwar': 168, 'osprey': 169,\n",
        "    'ovenbi1': 170, 'palwar': 171, 'pasfly': 172, 'pecsan': 173, 'perfal': 174,\n",
        "    'phaino': 175, 'pibgre': 176, 'pilwoo': 177, 'pingro': 178, 'pinjay': 179,\n",
        "    'pinsis': 180, 'pinwar': 181, 'plsvir': 182, 'prawar': 183, 'purfin': 184,\n",
        "    'pygnut': 185, 'rebmer': 186, 'rebnut': 187, 'rebsap': 188, 'rebwoo': 189,\n",
        "    'redcro': 190, 'redhea': 191, 'reevir1': 192, 'renpha': 193, 'reshaw': 194,\n",
        "    'rethaw': 195, 'rewbla': 196, 'ribgul': 197, 'rinduc': 198, 'robgro': 199,\n",
        "    'rocpig': 200, 'rocwre': 201, 'rthhum': 202, 'ruckin': 203, 'rudduc': 204,\n",
        "    'rufgro': 205, 'rufhum': 206, 'rusbla': 207, 'sagspa1': 208, 'sagthr': 209,\n",
        "    'savspa': 210, 'saypho': 211, 'scatan': 212, 'scoori': 213, 'semplo': 214,\n",
        "    'semsan': 215, 'sheowl': 216, 'shshaw': 217, 'snobun': 218, 'snogoo': 219,\n",
        "    'solsan': 220, 'sonspa': 221, 'sora': 222, 'sposan': 223, 'spotow': 224,\n",
        "    'stejay': 225, 'swahaw': 226, 'swaspa': 227, 'swathr': 228, 'treswa': 229,\n",
        "    'truswa': 230, 'tuftit': 231, 'tunswa': 232, 'veery': 233, 'vesspa': 234,\n",
        "    'vigswa': 235, 'warvir': 236, 'wesblu': 237, 'wesgre': 238, 'weskin': 239,\n",
        "    'wesmea': 240, 'wessan': 241, 'westan': 242, 'wewpew': 243, 'whbnut': 244,\n",
        "    'whcspa': 245, 'whfibi': 246, 'whtspa': 247, 'whtswi': 248, 'wilfly': 249,\n",
        "    'wilsni1': 250, 'wiltur': 251, 'winwre3': 252, 'wlswar': 253, 'wooduc': 254,\n",
        "    'wooscj2': 255, 'woothr': 256, 'y00475': 257, 'yebfly': 258, 'yebsap': 259,\n",
        "    'yehbla': 260, 'yelwar': 261, 'yerwar': 262, 'yetvir': 263\n",
        "}\n",
        "\n",
        "INV_BIRD_CODE = {v: k for k, v in BIRD_CODE.items()}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.008128,
          "end_time": "2020-08-21T16:49:13.422113",
          "exception": false,
          "start_time": "2020-08-21T16:49:13.413985",
          "status": "completed"
        },
        "tags": [],
        "id": "TnwIOGqFsQu5",
        "colab_type": "text"
      },
      "source": [
        "# Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-21T16:49:13.453155Z",
          "iopub.status.busy": "2020-08-21T16:49:13.452173Z",
          "iopub.status.idle": "2020-08-21T16:49:13.501205Z",
          "shell.execute_reply": "2020-08-21T16:49:13.502371Z"
        },
        "papermill": {
          "duration": 0.070873,
          "end_time": "2020-08-21T16:49:13.502594",
          "exception": false,
          "start_time": "2020-08-21T16:49:13.431721",
          "status": "completed"
        },
        "tags": [],
        "id": "cZ25rXBVsQu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PERIOD = 5\n",
        "\n",
        "def mono_to_color(\n",
        "    X: np.ndarray, mean=None, std=None,\n",
        "    norm_max=None, norm_min=None, eps=1e-6\n",
        "):\n",
        "    # Stack X as [X,X,X]\n",
        "    X = np.stack([X, X, X], axis=-1)\n",
        "\n",
        "    # Standardize\n",
        "    mean = mean or X.mean()\n",
        "    X = X - mean\n",
        "    std = std or X.std()\n",
        "    Xstd = X / (std + eps)\n",
        "    _min, _max = Xstd.min(), Xstd.max()\n",
        "    norm_max = norm_max or _max\n",
        "    norm_min = norm_min or _min\n",
        "    if (_max - _min) > eps:\n",
        "        # Normalize to [0, 255]\n",
        "        V = Xstd\n",
        "        V[V < norm_min] = norm_min\n",
        "        V[V > norm_max] = norm_max\n",
        "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
        "        V = V.astype(np.uint8)\n",
        "    else:\n",
        "        # Just zero\n",
        "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
        "    return V\n",
        "\n",
        "class SpectrogramDataset(data.Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        file_list: tp.List[tp.List[str]], \n",
        "        img_size=224,\n",
        "        waveform_transforms=None, \n",
        "        spectrogram_transforms=None, \n",
        "        melspectrogram_parameters={},\n",
        "        one_hot_label=True\n",
        "    ):\n",
        "        self.file_list = file_list  # list of list: [file_path, ebird_code]\n",
        "        self.img_size = img_size\n",
        "        self.waveform_transforms = waveform_transforms\n",
        "        self.spectrogram_transforms = spectrogram_transforms\n",
        "        self.melspectrogram_parameters = melspectrogram_parameters\n",
        "        self.one_hot_label = one_hot_label\n",
        "        self.times = {'read':0.0, 'waveform':0.0, 'melspec':0.0, 'spectogram':0.0, 'image':0.0, 'label':0.0}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "    \n",
        "    def __getitem__(self, idx: int):\n",
        "        #print('reading',idx)\n",
        "        wav_path, ebird_code = self.file_list[idx]\n",
        "\n",
        "        t = time.time()\n",
        "        y, sr = sf.read(wav_path)\n",
        "        self.times['read'] = self.times['read'] + time.time() - t; t = time.time()\n",
        "\n",
        "        if self.waveform_transforms:\n",
        "            y = self.waveform_transforms(y)\n",
        "        else:\n",
        "            len_y = len(y)\n",
        "            effective_length = sr * PERIOD\n",
        "            if len_y < effective_length:\n",
        "                new_y = np.zeros(effective_length, dtype=y.dtype)\n",
        "                start = np.random.randint(effective_length - len_y)\n",
        "                new_y[start:start + len_y] = y\n",
        "                y = new_y.astype(np.float32)\n",
        "            elif len_y > effective_length:\n",
        "                start = np.random.randint(len_y - effective_length)\n",
        "                y = y[start:start + effective_length].astype(np.float32)\n",
        "            else:\n",
        "                y = y.astype(np.float32)\n",
        "        self.times['waveform'] = self.times['waveform'] + time.time() - t; t = time.time()\n",
        "\n",
        "        melspec = librosa.feature.melspectrogram(y, sr=sr, **self.melspectrogram_parameters)\n",
        "        melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
        "        self.times['melspec'] = self.times['melspec'] + time.time() - t; t = time.time()\n",
        "\n",
        "        if self.spectrogram_transforms:\n",
        "            melspec = self.spectrogram_transforms(melspec)\n",
        "        else:\n",
        "            pass\n",
        "        self.times['spectogram'] = self.times['spectogram'] + t - time.time(); t = time.time()\n",
        "        \n",
        "        image = mono_to_color(melspec)\n",
        "        height, width, _ = image.shape\n",
        "        image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
        "        image = np.moveaxis(image, 2, 0)\n",
        "        image = (image / 255.0).astype(np.float32)\n",
        "        self.times['image'] = self.times['image'] + time.time() - t; t = time.time()\n",
        "\n",
        "        # Labels in One Hot format\n",
        "        if self.one_hot_label:\n",
        "            labels = np.zeros(len(BIRD_CODE), dtype=\"f\")\n",
        "            labels[BIRD_CODE[ebird_code]] = 1\n",
        "        else:  # Labels in integer format\n",
        "            labels = BIRD_CODE[ebird_code]\n",
        "        self.times['label'] = self.times['label'] + time.time() - t; t = time.time()\n",
        "\n",
        "        return image, labels\n",
        "    \n",
        "\n",
        "def get_loaders_for_training(train_file_list: tp.List[str], val_file_list: tp.List[str], img_size=224, melspectogram_params={}, bs_train=50, bs_val=100, loss=None):\n",
        "    \"\"\"Function to return dataloaders\"\"\"\n",
        "    # CrossEntropyLoss requires integer format for the classes\n",
        "    one_hot_format = loss != torch.nn.CrossEntropyLoss\n",
        "    \n",
        "    # # make dataset\n",
        "    train_dataset = SpectrogramDataset(train_file_list, img_size=img_size, melspectrogram_parameters=melspectogram_params, one_hot_label=one_hot_format)\n",
        "    val_dataset   = SpectrogramDataset(val_file_list, img_size=img_size, melspectrogram_parameters=melspectogram_params, one_hot_label=one_hot_format)\n",
        "    # # make dataloader\n",
        "    train_loader = data.DataLoader(train_dataset, shuffle=True,  num_workers=6, drop_last=True,  pin_memory=True, batch_size=bs_train)\n",
        "    val_loader   = data.DataLoader(val_dataset,   shuffle=False, num_workers=6, drop_last=False, pin_memory=True, batch_size=bs_val)\n",
        "    \n",
        "    return train_loader, val_loader"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.009747,
          "end_time": "2020-08-21T16:49:13.522076",
          "exception": false,
          "start_time": "2020-08-21T16:49:13.512329",
          "status": "completed"
        },
        "tags": [],
        "id": "gh4IDb9ysQu9",
        "colab_type": "text"
      },
      "source": [
        "# Experiment Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-21T16:49:13.557378Z",
          "iopub.status.busy": "2020-08-21T16:49:13.554125Z",
          "iopub.status.idle": "2020-08-21T16:49:13.559020Z",
          "shell.execute_reply": "2020-08-21T16:49:13.560131Z"
        },
        "papermill": {
          "duration": 0.029733,
          "end_time": "2020-08-21T16:49:13.560408",
          "exception": false,
          "start_time": "2020-08-21T16:49:13.530675",
          "status": "completed"
        },
        "tags": [],
        "id": "ECZSGjJOsQu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_EXPERIMENTS = 1  # Normally not more than one run per commit\n",
        "FOLD = 0 # Each run should cover a single fold\n",
        "\n",
        "# DATASET PARAMS\n",
        "IMG_SIZE = [224] * N_EXPERIMENTS\n",
        "MELSPECTOGRAM_PARAMS = [{'n_mels':128, 'fmin':20, 'fmax':16000}] * N_EXPERIMENTS\n",
        "\n",
        "# DATALOADER PARAMS\n",
        "BS_TRAIN = [4]\n",
        "BS_VAL = [4]\n",
        "\n",
        "# MODEL PARAMS\n",
        "MODEL = [0]\n",
        "\n",
        "# LOSS FUNCTION\n",
        "LOSS = [torch.nn.CrossEntropyLoss]\n",
        "        #torch.nn.BCEWithLogitsLoss\n",
        "\n",
        "# LR SCHEDULER\n",
        "LR = [torch.optim.lr_scheduler.ReduceLROnPlateau] * N_EXPERIMENTS\n",
        "#LR = [torch.optim.lr_scheduler.CosineAnnealingLR] * N_EXPERIMENTS\n",
        "LR_PARAMS = [dict( mode='min',\n",
        "                   factor=0.5,\n",
        "                   patience=1,\n",
        "                   verbose=False, \n",
        "                   threshold=0.0001,\n",
        "                   threshold_mode='abs',\n",
        "                   cooldown=0, \n",
        "                   min_lr=1e-8,\n",
        "                   eps=1e-08\n",
        "                )] * N_EXPERIMENTS\n",
        "#LR_PARAMS = [dict(T_max=10)] * N_EXPERIMENTS\n",
        "\n",
        "# HALF PRECISION\n",
        "HP = [False] * N_EXPERIMENTS\n",
        "\n",
        "# GLOBAL PARAMETERS\n",
        "EPOCHS=45\n",
        "N_CLASSES = 264\n",
        "DISPLAY_PLOT=True"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.011356,
          "end_time": "2020-08-21T16:49:13.584998",
          "exception": false,
          "start_time": "2020-08-21T16:49:13.573642",
          "status": "completed"
        },
        "tags": [],
        "id": "JTjTwRNDsQvA",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-21T16:49:13.615655Z",
          "iopub.status.busy": "2020-08-21T16:49:13.613827Z",
          "iopub.status.idle": "2020-08-21T16:49:13.623848Z",
          "shell.execute_reply": "2020-08-21T16:49:13.624546Z"
        },
        "papermill": {
          "duration": 0.029331,
          "end_time": "2020-08-21T16:49:13.624718",
          "exception": false,
          "start_time": "2020-08-21T16:49:13.595387",
          "status": "completed"
        },
        "tags": [],
        "id": "VWHIO1OIsQvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Function to be called\n",
        "def get_model(model, n_classes):\n",
        "    if model == 0:\n",
        "        return get_model0( n_classes)\n",
        "    \n",
        "    if model == 1:\n",
        "        return get_model1( n_classes)\n",
        "\n",
        "\n",
        "# Model based on efficient net B0\n",
        "def get_model0(n_classes):\n",
        "    model = create_efn(0)\n",
        "    #del model.fc\n",
        "    # # use the same head as the baseline notebook.\n",
        "    n_features = model.classifier.in_features\n",
        "    \n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Linear(n_features, 512), nn.ReLU(), nn.Dropout(p=0.2),\n",
        "        nn.Linear(512, 512), nn.ReLU(), nn.Dropout(p=0.2),\n",
        "        nn.Linear(512, n_classes))\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Model based on resnest\n",
        "def get_model1(n_classes):\n",
        "    model = resnest_torch.resnest50_fast_1s1x64d(pretrained=True)\n",
        "    del model.fc\n",
        "    # # use the same head as the baseline notebook.\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(2048, 1024), nn.ReLU(), nn.Dropout(p=0.2),\n",
        "        nn.Linear(1024, 1024), nn.ReLU(), nn.Dropout(p=0.2),\n",
        "        nn.Linear(1024, n_classes))\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.00847,
          "end_time": "2020-08-21T16:49:13.642020",
          "exception": false,
          "start_time": "2020-08-21T16:49:13.633550",
          "status": "completed"
        },
        "tags": [],
        "id": "eH8bAMTNsQvD",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-21T16:49:13.667454Z",
          "iopub.status.busy": "2020-08-21T16:49:13.666684Z",
          "iopub.status.idle": "2020-08-21T16:49:13.753085Z",
          "shell.execute_reply": "2020-08-21T16:49:13.753903Z"
        },
        "papermill": {
          "duration": 0.103618,
          "end_time": "2020-08-21T16:49:13.754084",
          "exception": false,
          "start_time": "2020-08-21T16:49:13.650466",
          "status": "completed"
        },
        "tags": [],
        "id": "I4S1b9vbsQvE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2874139e-1c20-4017-efe2-40f35e814662"
      },
      "source": [
        "# Split train/val, taking fold 0 for experiments\n",
        "cv = MultiStratifiedKFold(5, train_all, ['ebird_code'], seed=42)\n",
        "train_idx, val_idx = cv.get_indices(fold=FOLD)\n",
        "train_files = train_all.iloc[train_idx][['file_path','ebird_code']].values.tolist()\n",
        "val_files = train_all.iloc[val_idx][['file_path','ebird_code']].values.tolist()\n",
        "print(f'Train set contains {len(train_files)} samples, Val set contains {len(val_files)}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set contains 17149 samples, Val set contains 4226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-21T16:49:13.791115Z",
          "iopub.status.busy": "2020-08-21T16:49:13.785781Z",
          "iopub.status.idle": "2020-08-21T21:37:47.760273Z",
          "shell.execute_reply": "2020-08-21T21:37:47.761272Z"
        },
        "papermill": {
          "duration": 17313.998057,
          "end_time": "2020-08-21T21:37:47.761528",
          "exception": false,
          "start_time": "2020-08-21T16:49:13.763471",
          "status": "completed"
        },
        "tags": [],
        "id": "TF8QasMfsQvH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e3a2268a-105d-4379-8ab4-c8d1eceec763"
      },
      "source": [
        "for i in range(N_EXPERIMENTS):\n",
        "    print(f'********** EXPERIMENT {i} **********')\n",
        "    print(f'***** img size {IMG_SIZE[i]} *****')\n",
        "    print(f'***** bs train {BS_TRAIN[i]} *****')\n",
        "    print(f'***** bs val {BS_VAL[i]} *****')\n",
        "    print(f'***** model {MODEL[i]} *****')\n",
        "    print(f'***** scheduler class {LR[i]} *****')\n",
        "    print(f'***** loss class {LOSS[i]} *****')\n",
        "    print(f'***** half precission {HP[i]} *****')\n",
        "    print(f'**********************************\\n')\n",
        "\n",
        "    # Create Data Loaders\n",
        "    train_loader, val_loader = get_loaders_for_training(train_file_list = train_files,\n",
        "                                                        val_file_list = val_files,\n",
        "                                                        img_size = IMG_SIZE[i],\n",
        "                                                        melspectogram_params = MELSPECTOGRAM_PARAMS[i],\n",
        "                                                        bs_train = BS_TRAIN[i],\n",
        "                                                        bs_val = BS_VAL[i],\n",
        "                                                        loss = LOSS[i]\n",
        "                                                        )\n",
        "    print(f'Training on  {len(train_loader)} batches, validating on {len(val_loader)} batches')\n",
        "    \n",
        "    # Load Model\n",
        "    device = torch.device('cuda:0')\n",
        "    model = get_model(MODEL[i], N_CLASSES)\n",
        "    model.to(device)\n",
        "    \n",
        "    # Create fitter object\n",
        "    if HP[i]:\n",
        "        fitter = TorchFitterHP(model, device, loss=LOSS[i](), n_epochs=EPOCHS, lr=0.001, scheduler_class = LR[i], scheduler_params = LR_PARAMS[i], verbose=1, early_stopping=5)\n",
        "    else:\n",
        "        fitter = TorchFitter(model, device, loss=LOSS[i](), n_epochs=EPOCHS, lr=0.001, scheduler_class = LR[i], scheduler_params = LR_PARAMS[i], verbose=1, early_stopping=5)\n",
        "    history = fitter.fit(train_loader, val_loader)\n",
        "    \n",
        "    # Calculate score on validation set\n",
        "    model = fitter.model\n",
        "    model.eval()\n",
        "    \n",
        "    labels = []\n",
        "    outputs = []\n",
        "    with torch.no_grad():\n",
        "        for img, ls in tqdm(val_loader):\n",
        "            outputs += np.argmax(model(img.to(device)).cpu().numpy(), axis=1).tolist()\n",
        "            labels +=  np.argmax(ls.numpy(), axis=1).tolist() if len(ls.shape) > 1 else ls.numpy().tolist()\n",
        "\n",
        "    oof_score = f1_score(y_true=labels, y_pred=outputs, average='micro')\n",
        "    \n",
        "    print(f'********** OOF F1 MICRO: {oof_score} **********')\n",
        "    \n",
        "    # PLOT TRAINING\n",
        "    if DISPLAY_PLOT:\n",
        "        plt.figure(figsize=(15,5))\n",
        "        plt.plot(np.arange(len(history)), history['train'],'-o',label='Train Loss',color='#ff7f0e')\n",
        "        plt.plot(np.arange(len(history)), history['val'],'-o',label='Val Loss',color='#1f77b4')\n",
        "        x = np.argmin( history['val'] ); y = np.min( history['val'] )\n",
        "        xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n",
        "        plt.text(x-0.03*xdist,y-0.13*ydist,'min loss\\n%.2f'%y,size=14)\n",
        "        plt.ylabel('Loss',size=14); plt.xlabel('Epoch',size=14)\n",
        "        plt.legend(loc=2)\n",
        "        \n",
        "        plt2 = plt.gca().twinx()\n",
        "        plt2.plot(np.arange(len(history)),history['lr'],'-o',label='LR',color='#2ca02c')\n",
        "        plt.ylabel('LR',size=14)\n",
        "        \n",
        "        plt.title('Experiment %i'%i,size=18)\n",
        "        plt.legend(loc=3)\n",
        "        plt.show()\n",
        "    \n",
        "    print('\\n')\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "********** EXPERIMENT 0 **********\n",
            "***** img size 224 *****\n",
            "***** bs train 4 *****\n",
            "***** bs val 4 *****\n",
            "***** model 0 *****\n",
            "***** scheduler class <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'> *****\n",
            "***** loss class <class 'torch.nn.modules.loss.CrossEntropyLoss'> *****\n",
            "***** half precission False *****\n",
            "**********************************\n",
            "\n",
            "Training on  4287 batches, validating on 1057 batches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b0_aa-827b6e33.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_b0_aa-827b6e33.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitter prepared. Device is cuda:0\n",
            "\n",
            "2020-08-23T21:19:59.962348\n",
            "LR: 0.001\n",
            "[RESULT]: Train. Epoch: 0, summary_loss: 5.55713, time: 4631.80973\n",
            "[RESULT]: Val. Epoch: 0, summary_loss: 5.51704, time: 1198.80557\n",
            "Validation loss improved from 100000 to 5.5170376067245055 and model is saved to ./models/best-checkpoint-000epoch.bin\n",
            "\n",
            "2020-08-23T22:57:10.935271\n",
            "LR: 0.001\n",
            "[RESULT]: Train. Epoch: 1, summary_loss: 5.53000, time: 4456.73989\n",
            "[RESULT]: Val. Epoch: 1, summary_loss: 5.51368, time: 1262.43706\n",
            "Validation loss improved from 5.5170376067245055 to 5.513684289691237 and model is saved to ./models/best-checkpoint-001epoch.bin\n",
            "\n",
            "2020-08-24T00:32:30.437155\n",
            "LR: 0.001\n",
            "[RESULT]: Train. Epoch: 2, summary_loss: 5.52697, time: 4743.99905\n",
            "[RESULT]: Val. Epoch: 2, summary_loss: 5.51326, time: 1170.01731\n",
            "Validation loss improved from 5.513684289691237 to 5.513256921736595 and model is saved to ./models/best-checkpoint-002epoch.bin\n",
            "\n",
            "2020-08-24T02:11:04.778949\n",
            "LR: 0.001\n",
            "[RESULT]: Train. Epoch: 3, summary_loss: 5.52599, time: 4595.34908\n",
            "[RESULT]: Val. Epoch: 3, summary_loss: 5.51293, time: 1143.63696\n",
            "Validation loss improved from 5.513256921736595 to 5.512929690487849 and model is saved to ./models/best-checkpoint-003epoch.bin\n",
            "\n",
            "2020-08-24T03:46:44.083690\n",
            "LR: 0.001\n",
            "[RESULT]: Train. Epoch: 4, summary_loss: 5.52526, time: 4487.05352\n",
            "[RESULT]: Val. Epoch: 4, summary_loss: 5.51396, time: 1116.50134\n",
            "\n",
            "2020-08-24T05:20:07.804700\n",
            "LR: 0.001\n",
            "[RESULT]: Train. Epoch: 5, summary_loss: 5.52605, time: 4467.29414\n",
            "[RESULT]: Val. Epoch: 5, summary_loss: 5.51369, time: 1097.02460\n",
            "\n",
            "2020-08-24T06:52:52.281963\n",
            "LR: 0.0005\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-590d3ccc682c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mfitter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTorchFitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOSS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLR_PARAMS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Calculate score on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/benatools/torch/fitter.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_loader, validation_loader)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;31m# Run one training epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0msummary_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg\u001b[0m  \u001b[0;31m# training loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/benatools/torch/fitter.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# run epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}