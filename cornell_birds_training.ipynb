{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "papermill": {
      "duration": 17359.838188,
      "end_time": "2020-08-21T21:37:49.849044",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2020-08-21T16:48:30.010856",
      "version": "2.1.0"
    },
    "colab": {
      "name": "cornell-birds-training.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benayas1/ALV_Framework/blob/master/cornell_birds_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.006096,
          "end_time": "2020-08-21T16:48:34.103941",
          "exception": false,
          "start_time": "2020-08-21T16:48:34.097845",
          "status": "completed"
        },
        "tags": [],
        "id": "6f_mMz3GsQuj",
        "colab_type": "text"
      },
      "source": [
        "# Training BirdSongs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "execution": {
          "iopub.execute_input": "2020-08-21T16:48:34.149928Z",
          "iopub.status.busy": "2020-08-21T16:48:34.143829Z",
          "iopub.status.idle": "2020-08-21T16:49:11.822933Z",
          "shell.execute_reply": "2020-08-21T16:49:11.821851Z"
        },
        "papermill": {
          "duration": 37.69724,
          "end_time": "2020-08-21T16:49:11.823059",
          "exception": false,
          "start_time": "2020-08-21T16:48:34.125819",
          "status": "completed"
        },
        "tags": [],
        "id": "geTlZ9vjsQuo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a5f96e8a-24c4-40e7-f379-d764c7e01507"
      },
      "source": [
        "# Import apex for mixed precision training\n",
        "#!cd /kaggle/input/apexpytorch/ && pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./ >> /dev/null\n",
        "\n",
        "#!wget https://github.com/benayas1/benatools/archive/master.zip -P bena\n",
        "#!unzip bena/master.zip\n",
        "\n",
        "!pip install benatools >> /dev/null\n",
        "\n",
        "# Install resnest\n",
        "#!pip install ../input/resnest50-fast-package/resnest-0.0.6b20200701/resnest/ >> /dev/null\n",
        "!pip install soundfile\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from pathlib import Path\n",
        "import typing as tp\n",
        "import cv2\n",
        "import librosa\n",
        "import random\n",
        "import audioread\n",
        "import soundfile as sf\n",
        "import os\n",
        "import time as time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import benatools as bena\n",
        "from benatools.tools import MultiStratifiedKFold\n",
        "from benatools.torch.fitter import TorchFitter\n",
        "from benatools.torch.efficient_net import create_efn\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "\n",
        "!pip install gcsfs\n",
        "import gcsfs\n",
        "from google.colab import auth\n",
        "from google.cloud import storage\n",
        "\n",
        "\n",
        "#from apex import amp\n",
        "\n",
        "#import resnest.torch as resnest_torch\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "\n",
        "COLAB = True\n",
        "\n",
        "if COLAB:\n",
        "    os.environ.setdefault(\"GCLOUD_PROJECT\", \"omega-cosmos-116215\")\n",
        "    GS_BUCKET = 'benayas_kaggle'\n",
        "    !echo \"deb http://packages.cloud.google.com/apt gcsfuse-`lsb_release -c -s` main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list\n",
        "    !curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "    !sudo apt-get -y -q update\n",
        "    !sudo apt-get -y -q install gcsfuse\n",
        "    auth.authenticate_user()\n",
        "    !mkdir -p data\n",
        "    !gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 {GS_BUCKET} data\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.6/dist-packages (0.10.3.post1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gcsfs) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.4.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from gcsfs) (4.4.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.6/dist-packages (from gcsfs) (3.6.2)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (1.17.2)\n",
            "Requirement already satisfied: fsspec>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2.10)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (1.5.1)\n",
            "Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (1.1.0)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (3.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (19.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (3.7.4.2)\n",
            "Requirement already satisfied: multidict<5.0,>=4.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (4.7.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (49.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.6)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.8)\n",
            "deb http://packages.cloud.google.com/apt gcsfuse-bionic main\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   653  100   653    0     0  19787      0 --:--:-- --:--:-- --:--:-- 19787\n",
            "OK\n",
            "Hit:1 http://packages.cloud.google.com/apt gcsfuse-bionic InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:13 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Hit:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "gcsfuse is already the newest version (0.30.0).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 60 not upgraded.\n",
            "Using mount point: /content/data\n",
            "Opening GCS connection...\n",
            "Opening bucket...\n",
            "Mounting file system...\n",
            "daemonize.Run: readFromProcess: sub-process: mountWithArgs: mountWithConn: Mount: mount: running fusermount: exit status 1\n",
            "\n",
            "stderr:\n",
            "fusermount: mountpoint is not empty\n",
            "fusermount: if you are sure this is safe, use the 'nonempty' mount option\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-21T16:49:11.842194Z",
          "iopub.status.busy": "2020-08-21T16:49:11.841448Z",
          "iopub.status.idle": "2020-08-21T16:49:11.847344Z",
          "shell.execute_reply": "2020-08-21T16:49:11.846833Z"
        },
        "papermill": {
          "duration": 0.018968,
          "end_time": "2020-08-21T16:49:11.847439",
          "exception": false,
          "start_time": "2020-08-21T16:49:11.828471",
          "status": "completed"
        },
        "tags": [],
        "id": "zmbBSKUDsQus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Seed\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    \n",
        "seed_everything(42)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.004918,
          "end_time": "2020-08-21T16:49:11.857601",
          "exception": false,
          "start_time": "2020-08-21T16:49:11.852683",
          "status": "completed"
        },
        "tags": [],
        "id": "IBFVmIm8sQuv",
        "colab_type": "text"
      },
      "source": [
        "# Read Data\n",
        "Read data from resampled datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-21T16:49:11.877218Z",
          "iopub.status.busy": "2020-08-21T16:49:11.876416Z",
          "iopub.status.idle": "2020-08-21T16:49:12.195754Z",
          "shell.execute_reply": "2020-08-21T16:49:12.196270Z"
        },
        "papermill": {
          "duration": 0.333707,
          "end_time": "2020-08-21T16:49:12.196418",
          "exception": false,
          "start_time": "2020-08-21T16:49:11.862711",
          "status": "completed"
        },
        "tags": [],
        "id": "VacvvoFKsQuw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "f0bbc9bf-e7fe-4a55-f1cf-d180eca840fa"
      },
      "source": [
        "%time\n",
        "\n",
        "def get_df_kaggle(TRAIN_RESAMPLED_AUDIO_DIRS, train_df):\n",
        "    print('Data will be loaded from Kaggle Platform')\n",
        "    tmp_list = []\n",
        "    for audio_d in TRAIN_RESAMPLED_AUDIO_DIRS:\n",
        "        if not audio_d.exists():\n",
        "            continue\n",
        "        for ebird_d in audio_d.iterdir():\n",
        "            if ebird_d.is_file():\n",
        "                continue\n",
        "            for wav_f in ebird_d.iterdir():\n",
        "                tmp_list.append([ebird_d.name, wav_f.name, wav_f.as_posix()])\n",
        "                \n",
        "    train_wav_path_exist = pd.DataFrame(tmp_list, columns=[\"ebird_code\", \"resampled_filename\", \"file_path\"])\n",
        "    del tmp_list\n",
        "    train_all = pd.merge(train, train_wav_path_exist, on=[\"ebird_code\", \"resampled_filename\"], how=\"inner\")\n",
        "\n",
        "    print(train.shape)\n",
        "    print(train_wav_path_exist.shape)\n",
        "    print(train_all.shape)\n",
        "    return train_all\n",
        "\n",
        "def get_df_colab(TRAIN_RESAMPLED_AUDIO_DIRS, train_df, client):\n",
        "    print('Data will be loaded from GCS')\n",
        "    tmp_list = []\n",
        "    for audio_d in TRAIN_RESAMPLED_AUDIO_DIRS:\n",
        "        for f in glob.iglob(audio_d+'/*'):\n",
        "            if f[-4:] == '.csv':\n",
        "                continue\n",
        "            for wav_f in glob.iglob(f+'/*.wav'):\n",
        "                tmp_list.append( [f[f.rfind('/')+1:], wav_f[wav_f.rfind('/')+1:], wav_f] )\n",
        "\n",
        "    train_wav_path_exist = pd.DataFrame(tmp_list, columns=[\"ebird_code\", \"resampled_filename\", \"file_path\"])\n",
        "    del tmp_list\n",
        "    train_all = pd.merge(train, train_wav_path_exist, on=[\"ebird_code\", \"resampled_filename\"], how=\"inner\")\n",
        "\n",
        "    print(train.shape)\n",
        "    print(train_wav_path_exist.shape)\n",
        "    print(train_all.shape)\n",
        "    return train_all\n",
        "\n",
        "if COLAB:\n",
        "    INPUT_ROOT  = \"/content/data/birdsong-recognition/\"\n",
        "    TRAIN_RESAMPLED_AUDIO_DIRS = [\n",
        "      INPUT_ROOT + \"birdsong-resampled-train-audio-{:0>2}\".format(i)  for i in range(5)\n",
        "    ]\n",
        "    train = pd.read_csv(TRAIN_RESAMPLED_AUDIO_DIRS[0] + \"/train_mod.csv\")\n",
        "    storage_client = storage.Client()\n",
        "    train_all = get_df_colab(TRAIN_RESAMPLED_AUDIO_DIRS, train, storage_client)\n",
        "else:\n",
        "    ROOT = Path.cwd().parent\n",
        "    INPUT_ROOT = ROOT / \"input\"\n",
        "    RAW_DATA = INPUT_ROOT / \"birdsong-recognition\"\n",
        "    TRAIN_AUDIO_DIR = RAW_DATA / \"train_audio\"\n",
        "    TRAIN_RESAMPLED_AUDIO_DIRS = [\n",
        "      INPUT_ROOT / \"birdsong-resampled-train-audio-{:0>2}\".format(i)  for i in range(5)\n",
        "    ]\n",
        "    TEST_AUDIO_DIR = RAW_DATA / \"test_audio\"\n",
        "\n",
        "    train = pd.read_csv(TRAIN_RESAMPLED_AUDIO_DIRS[0] / \"train_mod.csv\")\n",
        "    train_all = get_df_kaggle(TRAIN_RESAMPLED_AUDIO_DIRS, train)\n",
        "\n",
        "train_all"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
            "Wall time: 7.15 µs\n",
            "Data will be loaded from GCS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2020-08-21T16:49:13.366038Z",
          "iopub.status.busy": "2020-08-21T16:49:13.363577Z",
          "iopub.status.idle": "2020-08-21T16:49:13.403846Z",
          "shell.execute_reply": "2020-08-21T16:49:13.404671Z"
        },
        "papermill": {
          "duration": 0.070452,
          "end_time": "2020-08-21T16:49:13.404901",
          "exception": false,
          "start_time": "2020-08-21T16:49:13.334449",
          "status": "completed"
        },
        "tags": [],
        "id": "hDxhGxwhsQu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Coding the bird names\n",
        "\n",
        "BIRD_CODE = {\n",
        "    'aldfly': 0, 'ameavo': 1, 'amebit': 2, 'amecro': 3, 'amegfi': 4,\n",
        "    'amekes': 5, 'amepip': 6, 'amered': 7, 'amerob': 8, 'amewig': 9,\n",
        "    'amewoo': 10, 'amtspa': 11, 'annhum': 12, 'astfly': 13, 'baisan': 14,\n",
        "    'baleag': 15, 'balori': 16, 'banswa': 17, 'barswa': 18, 'bawwar': 19,\n",
        "    'belkin1': 20, 'belspa2': 21, 'bewwre': 22, 'bkbcuc': 23, 'bkbmag1': 24,\n",
        "    'bkbwar': 25, 'bkcchi': 26, 'bkchum': 27, 'bkhgro': 28, 'bkpwar': 29,\n",
        "    'bktspa': 30, 'blkpho': 31, 'blugrb1': 32, 'blujay': 33, 'bnhcow': 34,\n",
        "    'boboli': 35, 'bongul': 36, 'brdowl': 37, 'brebla': 38, 'brespa': 39,\n",
        "    'brncre': 40, 'brnthr': 41, 'brthum': 42, 'brwhaw': 43, 'btbwar': 44,\n",
        "    'btnwar': 45, 'btywar': 46, 'buffle': 47, 'buggna': 48, 'buhvir': 49,\n",
        "    'bulori': 50, 'bushti': 51, 'buwtea': 52, 'buwwar': 53, 'cacwre': 54,\n",
        "    'calgul': 55, 'calqua': 56, 'camwar': 57, 'cangoo': 58, 'canwar': 59,\n",
        "    'canwre': 60, 'carwre': 61, 'casfin': 62, 'caster1': 63, 'casvir': 64,\n",
        "    'cedwax': 65, 'chispa': 66, 'chiswi': 67, 'chswar': 68, 'chukar': 69,\n",
        "    'clanut': 70, 'cliswa': 71, 'comgol': 72, 'comgra': 73, 'comloo': 74,\n",
        "    'commer': 75, 'comnig': 76, 'comrav': 77, 'comred': 78, 'comter': 79,\n",
        "    'comyel': 80, 'coohaw': 81, 'coshum': 82, 'cowscj1': 83, 'daejun': 84,\n",
        "    'doccor': 85, 'dowwoo': 86, 'dusfly': 87, 'eargre': 88, 'easblu': 89,\n",
        "    'easkin': 90, 'easmea': 91, 'easpho': 92, 'eastow': 93, 'eawpew': 94,\n",
        "    'eucdov': 95, 'eursta': 96, 'evegro': 97, 'fiespa': 98, 'fiscro': 99,\n",
        "    'foxspa': 100, 'gadwal': 101, 'gcrfin': 102, 'gnttow': 103, 'gnwtea': 104,\n",
        "    'gockin': 105, 'gocspa': 106, 'goleag': 107, 'grbher3': 108, 'grcfly': 109,\n",
        "    'greegr': 110, 'greroa': 111, 'greyel': 112, 'grhowl': 113, 'grnher': 114,\n",
        "    'grtgra': 115, 'grycat': 116, 'gryfly': 117, 'haiwoo': 118, 'hamfly': 119,\n",
        "    'hergul': 120, 'herthr': 121, 'hoomer': 122, 'hoowar': 123, 'horgre': 124,\n",
        "    'horlar': 125, 'houfin': 126, 'houspa': 127, 'houwre': 128, 'indbun': 129,\n",
        "    'juntit1': 130, 'killde': 131, 'labwoo': 132, 'larspa': 133, 'lazbun': 134,\n",
        "    'leabit': 135, 'leafly': 136, 'leasan': 137, 'lecthr': 138, 'lesgol': 139,\n",
        "    'lesnig': 140, 'lesyel': 141, 'lewwoo': 142, 'linspa': 143, 'lobcur': 144,\n",
        "    'lobdow': 145, 'logshr': 146, 'lotduc': 147, 'louwat': 148, 'macwar': 149,\n",
        "    'magwar': 150, 'mallar3': 151, 'marwre': 152, 'merlin': 153, 'moublu': 154,\n",
        "    'mouchi': 155, 'moudov': 156, 'norcar': 157, 'norfli': 158, 'norhar2': 159,\n",
        "    'normoc': 160, 'norpar': 161, 'norpin': 162, 'norsho': 163, 'norwat': 164,\n",
        "    'nrwswa': 165, 'nutwoo': 166, 'olsfly': 167, 'orcwar': 168, 'osprey': 169,\n",
        "    'ovenbi1': 170, 'palwar': 171, 'pasfly': 172, 'pecsan': 173, 'perfal': 174,\n",
        "    'phaino': 175, 'pibgre': 176, 'pilwoo': 177, 'pingro': 178, 'pinjay': 179,\n",
        "    'pinsis': 180, 'pinwar': 181, 'plsvir': 182, 'prawar': 183, 'purfin': 184,\n",
        "    'pygnut': 185, 'rebmer': 186, 'rebnut': 187, 'rebsap': 188, 'rebwoo': 189,\n",
        "    'redcro': 190, 'redhea': 191, 'reevir1': 192, 'renpha': 193, 'reshaw': 194,\n",
        "    'rethaw': 195, 'rewbla': 196, 'ribgul': 197, 'rinduc': 198, 'robgro': 199,\n",
        "    'rocpig': 200, 'rocwre': 201, 'rthhum': 202, 'ruckin': 203, 'rudduc': 204,\n",
        "    'rufgro': 205, 'rufhum': 206, 'rusbla': 207, 'sagspa1': 208, 'sagthr': 209,\n",
        "    'savspa': 210, 'saypho': 211, 'scatan': 212, 'scoori': 213, 'semplo': 214,\n",
        "    'semsan': 215, 'sheowl': 216, 'shshaw': 217, 'snobun': 218, 'snogoo': 219,\n",
        "    'solsan': 220, 'sonspa': 221, 'sora': 222, 'sposan': 223, 'spotow': 224,\n",
        "    'stejay': 225, 'swahaw': 226, 'swaspa': 227, 'swathr': 228, 'treswa': 229,\n",
        "    'truswa': 230, 'tuftit': 231, 'tunswa': 232, 'veery': 233, 'vesspa': 234,\n",
        "    'vigswa': 235, 'warvir': 236, 'wesblu': 237, 'wesgre': 238, 'weskin': 239,\n",
        "    'wesmea': 240, 'wessan': 241, 'westan': 242, 'wewpew': 243, 'whbnut': 244,\n",
        "    'whcspa': 245, 'whfibi': 246, 'whtspa': 247, 'whtswi': 248, 'wilfly': 249,\n",
        "    'wilsni1': 250, 'wiltur': 251, 'winwre3': 252, 'wlswar': 253, 'wooduc': 254,\n",
        "    'wooscj2': 255, 'woothr': 256, 'y00475': 257, 'yebfly': 258, 'yebsap': 259,\n",
        "    'yehbla': 260, 'yelwar': 261, 'yerwar': 262, 'yetvir': 263\n",
        "}\n",
        "\n",
        "INV_BIRD_CODE = {v: k for k, v in BIRD_CODE.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.008128,
          "end_time": "2020-08-21T16:49:13.422113",
          "exception": false,
          "start_time": "2020-08-21T16:49:13.413985",
          "status": "completed"
        },
        "tags": [],
        "id": "TnwIOGqFsQu5",
        "colab_type": "text"
      },
      "source": [
        "# Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-21T16:49:13.453155Z",
          "iopub.status.busy": "2020-08-21T16:49:13.452173Z",
          "iopub.status.idle": "2020-08-21T16:49:13.501205Z",
          "shell.execute_reply": "2020-08-21T16:49:13.502371Z"
        },
        "papermill": {
          "duration": 0.070873,
          "end_time": "2020-08-21T16:49:13.502594",
          "exception": false,
          "start_time": "2020-08-21T16:49:13.431721",
          "status": "completed"
        },
        "tags": [],
        "id": "cZ25rXBVsQu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PERIOD = 5\n",
        "\n",
        "def mono_to_color(\n",
        "    X: np.ndarray, mean=None, std=None,\n",
        "    norm_max=None, norm_min=None, eps=1e-6\n",
        "):\n",
        "    # Stack X as [X,X,X]\n",
        "    X = np.stack([X, X, X], axis=-1)\n",
        "\n",
        "    # Standardize\n",
        "    mean = mean or X.mean()\n",
        "    X = X - mean\n",
        "    std = std or X.std()\n",
        "    Xstd = X / (std + eps)\n",
        "    _min, _max = Xstd.min(), Xstd.max()\n",
        "    norm_max = norm_max or _max\n",
        "    norm_min = norm_min or _min\n",
        "    if (_max - _min) > eps:\n",
        "        # Normalize to [0, 255]\n",
        "        V = Xstd\n",
        "        V[V < norm_min] = norm_min\n",
        "        V[V > norm_max] = norm_max\n",
        "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
        "        V = V.astype(np.uint8)\n",
        "    else:\n",
        "        # Just zero\n",
        "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
        "    return V\n",
        "\n",
        "class SpectrogramDataset(data.Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        file_list: tp.List[tp.List[str]], \n",
        "        img_size=224,\n",
        "        waveform_transforms=None, \n",
        "        spectrogram_transforms=None, \n",
        "        melspectrogram_parameters={},\n",
        "        one_hot_label=True\n",
        "    ):\n",
        "        self.file_list = file_list  # list of list: [file_path, ebird_code]\n",
        "        self.img_size = img_size\n",
        "        self.waveform_transforms = waveform_transforms\n",
        "        self.spectrogram_transforms = spectrogram_transforms\n",
        "        self.melspectrogram_parameters = melspectrogram_parameters\n",
        "        self.one_hot_label = one_hot_label\n",
        "        self.times = {'read':0.0, 'waveform':0.0, 'melspec':0.0, 'spectogram':0.0, 'image':0.0, 'label':0.0}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "    \n",
        "    def __getitem__(self, idx: int):\n",
        "        wav_path, ebird_code = self.file_list[idx]\n",
        "\n",
        "        t = time.time()\n",
        "        y, sr = sf.read(wav_path)\n",
        "        self.times['read'] = self.times['read'] + time.time() - t; t = time.time()\n",
        "\n",
        "        if self.waveform_transforms:\n",
        "            y = self.waveform_transforms(y)\n",
        "        else:\n",
        "            len_y = len(y)\n",
        "            effective_length = sr * PERIOD\n",
        "            if len_y < effective_length:\n",
        "                new_y = np.zeros(effective_length, dtype=y.dtype)\n",
        "                start = np.random.randint(effective_length - len_y)\n",
        "                new_y[start:start + len_y] = y\n",
        "                y = new_y.astype(np.float32)\n",
        "            elif len_y > effective_length:\n",
        "                start = np.random.randint(len_y - effective_length)\n",
        "                y = y[start:start + effective_length].astype(np.float32)\n",
        "            else:\n",
        "                y = y.astype(np.float32)\n",
        "        self.times['waveform'] = self.times['waveform'] + time.time() - t; t = time.time()\n",
        "\n",
        "        melspec = librosa.feature.melspectrogram(y, sr=sr, **self.melspectrogram_parameters)\n",
        "        melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
        "        self.times['melspec'] = self.times['melspec'] + time.time() - t; t = time.time()\n",
        "\n",
        "        if self.spectrogram_transforms:\n",
        "            melspec = self.spectrogram_transforms(melspec)\n",
        "        else:\n",
        "            pass\n",
        "        self.times['spectogram'] = self.times['spectogram'] + t - time.time(); t = time.time()\n",
        "        \n",
        "        image = mono_to_color(melspec)\n",
        "        height, width, _ = image.shape\n",
        "        image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
        "        image = np.moveaxis(image, 2, 0)\n",
        "        image = (image / 255.0).astype(np.float32)\n",
        "        self.times['image'] = self.times['image'] + time.time() - t; t = time.time()\n",
        "\n",
        "        # Labels in One Hot format\n",
        "        if self.one_hot_label:\n",
        "            labels = np.zeros(len(BIRD_CODE), dtype=\"f\")\n",
        "            labels[BIRD_CODE[ebird_code]] = 1\n",
        "        else:  # Labels in integer format\n",
        "            labels = BIRD_CODE[ebird_code]\n",
        "        self.times['label'] = self.times['label'] + time.time() - t; t = time.time()\n",
        "\n",
        "        return image, labels\n",
        "    \n",
        "\n",
        "def get_loaders_for_training(train_file_list: tp.List[str], val_file_list: tp.List[str], img_size=224, melspectogram_params={}, bs_train=50, bs_val=100, loss=None):\n",
        "    \"\"\"Function to return dataloaders\"\"\"\n",
        "    # CrossEntropyLoss requires integer format for the classes\n",
        "    one_hot_format = loss != torch.nn.CrossEntropyLoss\n",
        "    \n",
        "    # # make dataset\n",
        "    train_dataset = SpectrogramDataset(train_file_list, img_size=img_size, melspectrogram_parameters=melspectogram_params, one_hot_label=one_hot_format)\n",
        "    val_dataset   = SpectrogramDataset(val_file_list, img_size=img_size, melspectrogram_parameters=melspectogram_params, one_hot_label=one_hot_format)\n",
        "    # # make dataloader\n",
        "    train_loader = data.DataLoader(train_dataset, shuffle=True,  num_workers=6, drop_last=True,  pin_memory=True, batch_size=bs_train)\n",
        "    val_loader   = data.DataLoader(val_dataset,   shuffle=False, num_workers=6, drop_last=False, pin_memory=True, batch_size=bs_val)\n",
        "    \n",
        "    return train_loader, val_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.009747,
          "end_time": "2020-08-21T16:49:13.522076",
          "exception": false,
          "start_time": "2020-08-21T16:49:13.512329",
          "status": "completed"
        },
        "tags": [],
        "id": "gh4IDb9ysQu9",
        "colab_type": "text"
      },
      "source": [
        "# Experiment Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-21T16:49:13.557378Z",
          "iopub.status.busy": "2020-08-21T16:49:13.554125Z",
          "iopub.status.idle": "2020-08-21T16:49:13.559020Z",
          "shell.execute_reply": "2020-08-21T16:49:13.560131Z"
        },
        "papermill": {
          "duration": 0.029733,
          "end_time": "2020-08-21T16:49:13.560408",
          "exception": false,
          "start_time": "2020-08-21T16:49:13.530675",
          "status": "completed"
        },
        "tags": [],
        "id": "ECZSGjJOsQu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_EXPERIMENTS = 1  # Normally not more than one run per commit\n",
        "FOLD = 0 # Each run should cover a single fold\n",
        "\n",
        "# DATASET PARAMS\n",
        "IMG_SIZE = [224] * N_EXPERIMENTS\n",
        "MELSPECTOGRAM_PARAMS = [{'n_mels':128, 'fmin':20, 'fmax':16000}] * N_EXPERIMENTS\n",
        "\n",
        "# DATALOADER PARAMS\n",
        "BS_TRAIN = [64]\n",
        "BS_VAL = [64]\n",
        "\n",
        "# MODEL PARAMS\n",
        "MODEL = [0]\n",
        "\n",
        "# LOSS FUNCTION\n",
        "LOSS = [torch.nn.CrossEntropyLoss]\n",
        "        #torch.nn.BCEWithLogitsLoss\n",
        "\n",
        "# LR SCHEDULER\n",
        "LR = [torch.optim.lr_scheduler.ReduceLROnPlateau] * N_EXPERIMENTS\n",
        "#LR = [torch.optim.lr_scheduler.CosineAnnealingLR] * N_EXPERIMENTS\n",
        "LR_PARAMS = [dict( mode='min',\n",
        "                   factor=0.5,\n",
        "                   patience=1,\n",
        "                   verbose=False, \n",
        "                   threshold=0.0001,\n",
        "                   threshold_mode='abs',\n",
        "                   cooldown=0, \n",
        "                   min_lr=1e-8,\n",
        "                   eps=1e-08\n",
        "                )] * N_EXPERIMENTS\n",
        "#LR_PARAMS = [dict(T_max=10)] * N_EXPERIMENTS\n",
        "\n",
        "# HALF PRECISION\n",
        "HP = [False] * N_EXPERIMENTS\n",
        "\n",
        "# GLOBAL PARAMETERS\n",
        "EPOCHS=45\n",
        "N_CLASSES = 264\n",
        "DISPLAY_PLOT=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.011356,
          "end_time": "2020-08-21T16:49:13.584998",
          "exception": false,
          "start_time": "2020-08-21T16:49:13.573642",
          "status": "completed"
        },
        "tags": [],
        "id": "JTjTwRNDsQvA",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-21T16:49:13.615655Z",
          "iopub.status.busy": "2020-08-21T16:49:13.613827Z",
          "iopub.status.idle": "2020-08-21T16:49:13.623848Z",
          "shell.execute_reply": "2020-08-21T16:49:13.624546Z"
        },
        "papermill": {
          "duration": 0.029331,
          "end_time": "2020-08-21T16:49:13.624718",
          "exception": false,
          "start_time": "2020-08-21T16:49:13.595387",
          "status": "completed"
        },
        "tags": [],
        "id": "VWHIO1OIsQvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Function to be called\n",
        "def get_model(model, n_classes):\n",
        "    if model == 0:\n",
        "        return get_model0( n_classes)\n",
        "    \n",
        "    if model == 1:\n",
        "        return get_model1( n_classes)\n",
        "\n",
        "\n",
        "# Model based on efficient net B0\n",
        "def get_model0(n_classes):\n",
        "    model = create_efn(0)\n",
        "    #del model.fc\n",
        "    # # use the same head as the baseline notebook.\n",
        "    n_features = model.classifier.in_features\n",
        "    \n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Linear(n_features, 512), nn.ReLU(), nn.Dropout(p=0.2),\n",
        "        nn.Linear(512, 512), nn.ReLU(), nn.Dropout(p=0.2),\n",
        "        nn.Linear(512, n_classes))\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Model based on resnest\n",
        "def get_model1(n_classes):\n",
        "    model = resnest_torch.resnest50_fast_1s1x64d(pretrained=True)\n",
        "    del model.fc\n",
        "    # # use the same head as the baseline notebook.\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(2048, 1024), nn.ReLU(), nn.Dropout(p=0.2),\n",
        "        nn.Linear(1024, 1024), nn.ReLU(), nn.Dropout(p=0.2),\n",
        "        nn.Linear(1024, n_classes))\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.00847,
          "end_time": "2020-08-21T16:49:13.642020",
          "exception": false,
          "start_time": "2020-08-21T16:49:13.633550",
          "status": "completed"
        },
        "tags": [],
        "id": "eH8bAMTNsQvD",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-21T16:49:13.667454Z",
          "iopub.status.busy": "2020-08-21T16:49:13.666684Z",
          "iopub.status.idle": "2020-08-21T16:49:13.753085Z",
          "shell.execute_reply": "2020-08-21T16:49:13.753903Z"
        },
        "papermill": {
          "duration": 0.103618,
          "end_time": "2020-08-21T16:49:13.754084",
          "exception": false,
          "start_time": "2020-08-21T16:49:13.650466",
          "status": "completed"
        },
        "tags": [],
        "id": "I4S1b9vbsQvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split train/val, taking fold 0 for experiments\n",
        "cv = MultiStratifiedKFold(5, train_all, ['ebird_code'], seed=42)\n",
        "train_idx, val_idx = cv.get_indices(fold=FOLD)\n",
        "train_files = train_all.iloc[train_idx][['file_path','ebird_code']].values.tolist()\n",
        "val_files = train_all.iloc[val_idx][['file_path','ebird_code']].values.tolist()\n",
        "print(f'Train set contains {len(train_files)} samples, Val set contains {len(val_files)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-21T16:49:13.791115Z",
          "iopub.status.busy": "2020-08-21T16:49:13.785781Z",
          "iopub.status.idle": "2020-08-21T21:37:47.760273Z",
          "shell.execute_reply": "2020-08-21T21:37:47.761272Z"
        },
        "papermill": {
          "duration": 17313.998057,
          "end_time": "2020-08-21T21:37:47.761528",
          "exception": false,
          "start_time": "2020-08-21T16:49:13.763471",
          "status": "completed"
        },
        "tags": [],
        "id": "TF8QasMfsQvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(N_EXPERIMENTS):\n",
        "    print(f'********** EXPERIMENT {i} **********')\n",
        "    print(f'***** img size {IMG_SIZE[i]} *****')\n",
        "    print(f'***** bs train {BS_TRAIN[i]} *****')\n",
        "    print(f'***** bs val {BS_VAL[i]} *****')\n",
        "    print(f'***** model {MODEL[i]} *****')\n",
        "    print(f'***** scheduler class {LR[i]} *****')\n",
        "    print(f'***** loss class {LOSS[i]} *****')\n",
        "    print(f'***** half precission {HP[i]} *****')\n",
        "    print(f'**********************************\\n')\n",
        "\n",
        "    # Create Data Loaders\n",
        "    train_loader, val_loader = get_loaders_for_training(train_file_list = train_files,\n",
        "                                                        val_file_list = val_files,\n",
        "                                                        img_size = IMG_SIZE[i],\n",
        "                                                        melspectogram_params = MELSPECTOGRAM_PARAMS[i],\n",
        "                                                        bs_train = BS_TRAIN[i],\n",
        "                                                        bs_val = BS_VAL[i],\n",
        "                                                        loss = LOSS[i]\n",
        "                                                        )\n",
        "    print(f'Training on  {len(train_loader)} batches, validating on {len(val_loader)} batches')\n",
        "    \n",
        "    # Load Model\n",
        "    device = torch.device('cuda:0')\n",
        "    model = get_model(MODEL[i], N_CLASSES)\n",
        "    model.to(device)\n",
        "    \n",
        "    # Create fitter object\n",
        "    if HP[i]:\n",
        "        fitter = TorchFitterHP(model, device, loss=LOSS[i](), n_epochs=EPOCHS, lr=0.001, scheduler_class = LR[i], scheduler_params = LR_PARAMS[i], verbose=10, early_stopping=5)\n",
        "    else:\n",
        "        fitter = TorchFitter(model, device, loss=LOSS[i](), n_epochs=EPOCHS, lr=0.001, scheduler_class = LR[i], scheduler_params = LR_PARAMS[i], verbose=10, early_stopping=5)\n",
        "    history = fitter.fit(train_loader, val_loader)\n",
        "    \n",
        "    # Calculate score on validation set\n",
        "    model = fitter.model\n",
        "    model.eval()\n",
        "    \n",
        "    labels = []\n",
        "    outputs = []\n",
        "    with torch.no_grad():\n",
        "        for img, ls in tqdm(val_loader):\n",
        "            outputs += np.argmax(model(img.to(device)).cpu().numpy(), axis=1).tolist()\n",
        "            labels +=  np.argmax(ls.numpy(), axis=1).tolist() if len(ls.shape) > 1 else ls.numpy().tolist()\n",
        "\n",
        "    oof_score = f1_score(y_true=labels, y_pred=outputs, average='micro')\n",
        "    \n",
        "    print(f'********** OOF F1 MICRO: {oof_score} **********')\n",
        "    \n",
        "    # PLOT TRAINING\n",
        "    if DISPLAY_PLOT:\n",
        "        plt.figure(figsize=(15,5))\n",
        "        plt.plot(np.arange(len(history)), history['train'],'-o',label='Train Loss',color='#ff7f0e')\n",
        "        plt.plot(np.arange(len(history)), history['val'],'-o',label='Val Loss',color='#1f77b4')\n",
        "        x = np.argmin( history['val'] ); y = np.min( history['val'] )\n",
        "        xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n",
        "        plt.text(x-0.03*xdist,y-0.13*ydist,'min loss\\n%.2f'%y,size=14)\n",
        "        plt.ylabel('Loss',size=14); plt.xlabel('Epoch',size=14)\n",
        "        plt.legend(loc=2)\n",
        "        \n",
        "        plt2 = plt.gca().twinx()\n",
        "        plt2.plot(np.arange(len(history)),history['lr'],'-o',label='LR',color='#2ca02c')\n",
        "        plt.ylabel('LR',size=14)\n",
        "        \n",
        "        plt.title('Experiment %i'%i,size=18)\n",
        "        plt.legend(loc=3)\n",
        "        plt.show()\n",
        "    \n",
        "    print('\\n')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}